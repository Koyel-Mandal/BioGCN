{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6U5qTjuYAyC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit\n",
        "!pip install shap\n",
        "!pip install xgboost\n",
        "!pip install catboost"
      ],
      "metadata": {
        "id": "6u_fWvXmYcal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import packages and modules\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import Draw, Descriptors, AllChem\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from itertools import combinations\n",
        "import IPython\n",
        "from IPython.display import display, Image as IPImage\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from rdkit import Chem\n",
        "from rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n",
        "import shap\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy import stats\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, balanced_accuracy_score, confusion_matrix, cohen_kappa_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "jtLX-5L2YW8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Excel file\n",
        "\n",
        "#sheet_names = pd.ExcelFile(\"D:\\Dataset_koyel\\CDRI_preprocessed.xlsx\").sheet_names\n",
        "#print(sheet_names)\n",
        "\n",
        "train_df = pd.read_excel('/content/drive/MyDrive/HOB/Dataset_CDRI.xlsx', sheet_name = \"Dataset\")\n",
        "print(train_df.shape)\n",
        "\n",
        "#print(df_first.head(5))\n",
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "pd.set_option('display.max_columns', None)  # Show all columns\n"
      ],
      "metadata": {
        "id": "kExNp-GxY6oG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_excel('/content/drive/MyDrive/HOB/Testing_drug.xlsx', sheet_name = \"test_data_pka_class\")\n",
        "print(test_df.shape)"
      ],
      "metadata": {
        "id": "oi6DDF8jZanW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning Preprocessing of the half life. Removed hours, around, approximtely, approx sign. Replaced \"-\" and \"–\" to \"to\"\n",
        "\n",
        "train_df['Half Life (hrs-1)'] = train_df['Half Life (hrs-1)'].apply(lambda x: re.sub(r'[≈<~]|\\bhours?\\.?\\b|\\bhr\\b|\\bh\\b|\\babout|\\baround|\\bapproximately|\\bapprox|\\bApproximately|\\bbetween', '', str(x), flags=re.IGNORECASE))\n",
        "train_df = train_df.apply(lambda x: str(x).strip() if isinstance(x, str) else x) #Remove space in starting and ending\n",
        "train_df['Half Life (hrs-1)'] = train_df['Half Life (hrs-1)'].apply(lambda x: x.replace(\"-\", \" to \") if isinstance(x, str) else x) # Replace - with 'to'\n",
        "train_df['Half Life (hrs-1)'] = train_df['Half Life (hrs-1)'].apply(lambda x: x.replace(\"–\", \" to \") if isinstance(x, str) else x) # Replace – with 'to'\n",
        "\n",
        "#print(train_df['Half Life (hrs-1)'])"
      ],
      "metadata": {
        "id": "bLIXesyaZlyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning Preprocessing of the half life. Removed hours, around, approximtely, approx sign. Replaced \"-\" and \"–\" to \"to\"\n",
        "\n",
        "test_df['Half Life (hrs-1)'] = test_df['Half Life (hrs-1)'].apply(lambda x: re.sub(r'[≈<~]|\\bhours?\\b|\\bhrs\\b', '', str(x), flags=re.IGNORECASE))\n",
        "test_df = test_df.apply(lambda x: str(x).strip() if isinstance(x, str) else x) #Remove space in starting and ending\n",
        "test_df['Half Life (hrs-1)'] = test_df['Half Life (hrs-1)'].apply(lambda x: x.replace(\"-\", \" to \") if isinstance(x, str) else x) # Replace - with 'to'\n",
        "test_df['Half Life (hrs-1)'] = test_df['Half Life (hrs-1)'].apply(lambda x: x.replace(\"–\", \" to \") if isinstance(x, str) else x) # Replace – with 'to'\n",
        "\n",
        "#print(test_df['Half Life (hrs-1)'])"
      ],
      "metadata": {
        "id": "Uasmw_nHZoph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_hours(value):\n",
        "    if 'to' in value:\n",
        "        min_value, second = map(str, value.split(' to'))\n",
        "        if 'days' in second:\n",
        "            max_value, string = map(str, second.split(' days'))\n",
        "            average_value = ((float(min_value) + float(max_value)) / 2) *24  # Convert days to hours\n",
        "            return average_value\n",
        "        elif 'day' in second:\n",
        "            max_value, string = map(str, second.split(' day'))\n",
        "            average_value = ((float(min_value) + float(max_value)) / 2) * 24  # Convert day to hours\n",
        "            return average_value\n",
        "        elif 'minutes' in second:\n",
        "            max_value, string = map(str, second.split(' minutes'))\n",
        "            average_value = ((float(min_value) + float(max_value)) / 2) / 60  # Convert minutes to hours\n",
        "            return average_value\n",
        "        elif 'min' in second:\n",
        "            max_value, string = map(str, second.split(' min'))\n",
        "            average_value = ((float(min_value) + float(max_value)) / 2) / 60  # Convert minutes to hours\n",
        "            return average_value\n",
        "        elif 'weeks' in second:\n",
        "            max_value, string = map(str, second.split(' weeks'))\n",
        "            average_value = ((float(min_value) + float(max_value)) / 2) * 7 * 24  # Convert weeks to hours\n",
        "            return average_value\n",
        "        else:\n",
        "            average_value = ((float(min_value) + float(second)) / 2)\n",
        "            return average_value\n",
        "    elif '±' in value:\n",
        "        min_value, string = map(str, value.split('±'))\n",
        "        return min_value\n",
        "    elif 'minutes' in value:\n",
        "        return float(value.split()[0]) / 60\n",
        "    elif 'min' in value:\n",
        "        return float(value.split()[0]) / 60\n",
        "    elif 'seconds' in value:\n",
        "        return float(value.split()[0]) / 3600\n",
        "    elif 'days' in value:\n",
        "        return float(value.split()[0]) * 24\n",
        "    elif 'day' in value:\n",
        "        return float(value.split()[0]) * 24\n",
        "    elif 'months' in value:\n",
        "        return float(value.split()[0]) * 30 * 24\n",
        "    elif 'weeks' in value:\n",
        "        return float(value.split()[0]) * 7 * 24\n",
        "    elif 'week' in value:\n",
        "        return float(value.split()[0]) * 7 * 24\n",
        "    elif 'years' in value:\n",
        "        return float(value.split()[0]) * 365 * 24\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "train_df['Half Life (hrs-1)'] = train_df['Half Life (hrs-1)'].apply(convert_to_hours)\n",
        "test_df['Half Life (hrs-1)'] = test_df['Half Life (hrs-1)'].apply(convert_to_hours)\n",
        "#print(df['Half Life (hrs-1)'])"
      ],
      "metadata": {
        "id": "JjmrCBjEZ0eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing the Oral Bioavailability column\n",
        "train_df['Oral Bioavailability'] = train_df['Oral Bioavailability'].apply(lambda x: re.sub(r'[≥]|\\babove', '', str(x)))\n",
        "train_df['Oral Bioavailability'] = train_df['Oral Bioavailability'].apply(lambda x: x.replace(\"-\", \" to \") if isinstance(x, str) else x) # Replace - with 'to'\n",
        "train_df['Oral Bioavailability'] = train_df['Oral Bioavailability'].apply(lambda x: x.replace(\"–\", \" to \") if isinstance(x, str) else x) # Replace – with 'to'\n",
        "#print(df['Oral Bioavailability'])"
      ],
      "metadata": {
        "id": "wApuEEWXZ3OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define two classes\n",
        "bio_lower_thresh = 19 #class 0\n",
        "bio_upper_thresh = 20 #class 1\n",
        "\n",
        "def class_define(value, bio_lower_thresh, bio_upper_thresh):\n",
        "    value = str(value)\n",
        "    if 'to' in value:\n",
        "        min_value, max_value = map(str, value.split('to'))\n",
        "        if float(min_value) <= bio_lower_thresh and float(max_value) <= bio_lower_thresh:\n",
        "            return 0\n",
        "        elif float(min_value) >= bio_upper_thresh and float(max_value) >= bio_upper_thresh:\n",
        "            return 1\n",
        "        else:\n",
        "            return -1\n",
        "    else:\n",
        "        if float(value) >= bio_upper_thresh:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "\n",
        "train_df['Class'] = train_df['Oral Bioavailability'].apply(lambda x: class_define(x, bio_lower_thresh, bio_upper_thresh))\n",
        "test_df['Class'] = test_df['Oral Bioavailability'].apply(lambda x: class_define(x, bio_lower_thresh, bio_upper_thresh))\n",
        "\n",
        "#dropped_df = original_df[original_df['Class'] == -1].reset_index(drop=True)\n",
        "#df = original_df[original_df['Class'] != -1].reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "BnIJ_53RZ7FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove ~\n",
        "\n",
        "train_df['M.Wt'] = train_df['M.Wt'].apply(lambda x: re.sub(r'[~]', '', str(x), flags=re.IGNORECASE))\n",
        "test_df['M.Wt'] = test_df['M.Wt'].apply(lambda x: re.sub(r'[~]', '', str(x), flags=re.IGNORECASE))\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl') as writer:\n",
        "    train_df.to_excel(writer, sheet_name='train_ready_data', index=False)\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode = 'a') as writer:\n",
        "    test_df.to_excel(writer, sheet_name='test_data', index=False)\n",
        "\n",
        "column_to_remove = 'Oral Bioavailability'  # Specify the name of the column you want to remove\n",
        "train_updated_df = train_df.drop(columns=[column_to_remove])\n",
        "test_updated_df = test_df.drop(columns=[column_to_remove])\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx',engine='openpyxl', mode='a') as writer:\n",
        "    train_updated_df.to_excel(writer, sheet_name='train_data_cnn', index=False)\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx',engine='openpyxl', mode='a') as writer:\n",
        "    test_updated_df.to_excel(writer, sheet_name='test_data_cnn', index=False)\n"
      ],
      "metadata": {
        "id": "ZcBWqH29Z9nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To see the structure of drugs\n",
        "\n",
        "def show_smiles_train(smiles):\n",
        "    molecules = [Chem.MolFromSmiles(smile) for smile in smiles]\n",
        "    #print(molecules)\n",
        "    img = Draw.MolsToGridImage(molecules[:20], molsPerRow=5, subImgSize=(400,400),\n",
        "                               legends=[f'LogP: {round(x, 2)}' for x in train_df['Log P']])\n",
        "    display(\"Click on the photo to zoom it\")\n",
        "    display(IPImage(\"/content/drive/MyDrive/HOB/Rerun/molecules.png\"))  # Use the renamed Image class\n",
        "\n",
        "\n",
        "\n",
        "show_smiles_train(train_df[\"Structure (SMILES)\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "Yb6rebQjaDy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chosen_descriptors = ['BalabanJ', 'BertzCT', 'Chi0', 'Chi0n', 'Chi0v', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3n', 'Chi3v', 'Chi4n', 'Chi4v',\n",
        "                      'EState_VSA1', 'EState_VSA10', 'EState_VSA11', 'EState_VSA2', 'EState_VSA3', 'EState_VSA4', 'EState_VSA5', 'EState_VSA6',\n",
        "                      'EState_VSA7', 'EState_VSA8', 'EState_VSA9', 'ExactMolWt', 'FpDensityMorgan1', 'FpDensityMorgan2', 'FpDensityMorgan3',\n",
        "                      'FractionCSP3', 'HallKierAlpha', 'HeavyAtomCount', 'HeavyAtomMolWt', 'Ipc', 'Kappa1', 'Kappa2', 'Kappa3', 'LabuteASA',\n",
        "                      'MaxAbsEStateIndex', 'MaxAbsPartialCharge', 'MaxEStateIndex', 'MaxPartialCharge', 'MinAbsEStateIndex', 'MinAbsPartialCharge',\n",
        "                      'MinEStateIndex', 'MinPartialCharge', 'MolLogP', 'MolMR', 'NHOHCount', 'NOCount', 'NumAliphaticCarbocycles',\n",
        "                      'NumAliphaticHeterocycles', 'NumAliphaticRings', 'NumAromaticCarbocycles', 'NumAromaticHeterocycles', 'NumAromaticRings',\n",
        "                      'NumHAcceptors', 'NumHDonors', 'NumHeteroatoms', 'NumRadicalElectrons',  'NumSaturatedCarbocycles',\n",
        "                      'NumSaturatedHeterocycles', 'NumSaturatedRings', 'NumValenceElectrons', 'PEOE_VSA1', 'PEOE_VSA10', 'PEOE_VSA11', 'PEOE_VSA12',\n",
        "                      'PEOE_VSA13', 'PEOE_VSA14', 'PEOE_VSA2', 'PEOE_VSA3', 'PEOE_VSA4', 'PEOE_VSA5', 'PEOE_VSA6', 'PEOE_VSA7', 'PEOE_VSA8', 'PEOE_VSA9',\n",
        "                      'RingCount', 'SMR_VSA1', 'SMR_VSA10', 'SMR_VSA2', 'SMR_VSA3', 'SMR_VSA4', 'SMR_VSA5', 'SMR_VSA6', 'SMR_VSA7', 'SMR_VSA8',\n",
        "                      'SMR_VSA9', 'SlogP_VSA1', 'SlogP_VSA10', 'SlogP_VSA11', 'SlogP_VSA12', 'SlogP_VSA2', 'SlogP_VSA3', 'SlogP_VSA4', 'SlogP_VSA5',\n",
        "                      'SlogP_VSA6', 'SlogP_VSA7', 'SlogP_VSA8', 'SlogP_VSA9', 'TPSA', 'VSA_EState1', 'VSA_EState10', 'VSA_EState2', 'VSA_EState3',\n",
        "                      'VSA_EState4', 'VSA_EState5', 'VSA_EState6', 'VSA_EState7', 'VSA_EState8', 'VSA_EState9', 'fr_Al_COO', 'fr_Al_OH',\n",
        "                      'fr_Al_OH_noTert', 'fr_ArN', 'fr_Ar_COO', 'fr_Ar_N', 'fr_Ar_NH', 'fr_Ar_OH', 'fr_COO', 'fr_COO2', 'fr_C_O', 'fr_C_O_noCOO',\n",
        "                      'fr_C_S', 'fr_HOCCN', 'fr_Imine', 'fr_NH0', 'fr_NH1', 'fr_NH2', 'fr_N_O', 'fr_Ndealkylation1', 'fr_Ndealkylation2', 'fr_Nhpyrrole',\n",
        "                      'fr_SH', 'fr_aldehyde', 'fr_alkyl_carbamate', 'fr_alkyl_halide', 'fr_allylic_oxid', 'fr_amide', 'fr_amidine', 'fr_aniline',\n",
        "                      'fr_aryl_methyl', 'fr_azide', 'fr_azo', 'fr_barbitur', 'fr_benzene', 'fr_benzodiazepine', 'fr_bicyclic', 'fr_diazo',\n",
        "                      'fr_dihydropyridine', 'fr_epoxide', 'fr_ester', 'fr_ether', 'fr_furan', 'fr_guanido', 'fr_halogen', 'fr_hdrzine', 'fr_hdrzone',\n",
        "                      'fr_imidazole', 'fr_imide', 'fr_isocyan', 'fr_isothiocyan', 'fr_ketone', 'fr_ketone_Topliss', 'fr_lactam', 'fr_lactone',\n",
        "                      'fr_methoxy', 'fr_morpholine', 'fr_nitrile', 'fr_nitro', 'fr_nitro_arom', 'fr_nitro_arom_nonortho', 'fr_nitroso', 'fr_oxazole',\n",
        "                      'fr_oxime', 'fr_para_hydroxylation', 'fr_phenol', 'fr_phenol_noOrthoHbond', 'fr_phos_acid', 'fr_phos_ester', 'fr_piperdine',\n",
        "                      'fr_piperzine', 'fr_priamide', 'fr_prisulfonamd', 'fr_pyridine', 'fr_quatN', 'fr_sulfide', 'fr_sulfonamd', 'fr_sulfone',\n",
        "                      'fr_term_acetylene', 'fr_tetrazole', 'fr_thiazole', 'fr_thiocyan', 'fr_thiophene', 'fr_unbrch_alkane', 'fr_urea', 'qed']\n",
        "#'NumRotatableBonds',  'MolWt',\n",
        "smiles_string = train_df[\"Structure (SMILES)\"]\n",
        "# Define a function to compute topological features from SMILES\n",
        "def compute_topological_features(smiles, chosen_descriptors):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None\n",
        "\n",
        "    mol_descriptor_calculator = MolecularDescriptorCalculator(chosen_descriptors)\n",
        "    list_of_descriptor_vals = list(mol_descriptor_calculator.CalcDescriptors(mol))\n",
        "    #print(list_of_descriptor_vals)\n",
        "    return list_of_descriptor_vals\n",
        "\n",
        "data = [compute_topological_features(smiles, chosen_descriptors) for smiles in smiles_string]\n",
        "descriptors_df = pd.DataFrame(data, columns = chosen_descriptors)\n",
        "#descriptors_df.insert(0, \"Drug_name\", descriptors_df.iloc[:, 0])\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    descriptors_df.to_excel(writer, sheet_name='descriptors', index=False)\n",
        "#print(descriptors_df)"
      ],
      "metadata": {
        "id": "iDoQUfl3acuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chosen_descriptors)"
      ],
      "metadata": {
        "id": "7oUULPUvakiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming df is your DataFrame\n",
        "col_thresh = 20\n",
        "column_sums = descriptors_df.sum(axis=0)  # Calculate column-wise sum\n",
        "\n",
        "# Filter out columns with sum as 0\n",
        "non_zero_sum_columns = column_sums[column_sums != 0].index\n",
        "descriptors_df_filtered = descriptors_df[non_zero_sum_columns]\n",
        "zero_percentage = (descriptors_df_filtered == 0).sum() / len(descriptors_df_filtered) * 100\n",
        "\n",
        "# Drop columns where the percentage of zeros exceeds col_thresh\n",
        "columns_to_keep = zero_percentage[zero_percentage <= col_thresh].index\n",
        "descriptors_df_filtered = descriptors_df[columns_to_keep ]\n",
        "\n",
        "print(descriptors_df_filtered.shape)\n",
        "\n",
        "#descriptors_df_filtered.to_csv('D:\\Dataset_koyel\\smiles2descriptors_filtered.csv', index = False)\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    descriptors_df_filtered.to_excel(writer, sheet_name='filtered_descriptors', index=False)"
      ],
      "metadata": {
        "id": "41KJfDv5apL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = descriptors_df_filtered.corr().abs()\n",
        "plt.figure(figsize=(30, 30))\n",
        "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', linewidths=.5,\n",
        "            cbar_kws={'label': 'Correlation Coefficient', 'shrink': 0.5},\n",
        "            xticklabels=corr_matrix.columns, yticklabels=corr_matrix.columns)\n",
        "plt.xticks(fontsize=16, rotation=90)\n",
        "plt.yticks(fontsize=16, rotation=0)\n",
        "plt.xlabel('Features', fontsize=16)\n",
        "plt.ylabel('Features', fontsize=16)\n",
        "#plt.title('Correlation Matrix', fontsize=20)\n",
        "plt.savefig('/content/drive/MyDrive/HOB/Rerun/correlation_matrix.eps', format='eps')\n",
        "plt.savefig('/content/drive/MyDrive/HOB/Rerun/correlation_matrix.png', format='png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CdlVLn1hav2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptors_df_filtered.shape"
      ],
      "metadata": {
        "id": "A8PjDrFha0rF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# Find features with correlation greater than a threshold (e.g., 0.9)\n",
        "threshold = 0.9\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "\n",
        "# Drop the features\n",
        "df_reduced = descriptors_df_filtered.drop(columns=to_drop)\n",
        "df_reduced.shape\n",
        "\n",
        "print(df_reduced.columns)\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    df_reduced.to_excel(writer, sheet_name='df_reduced', index=False)"
      ],
      "metadata": {
        "id": "iGRpsoqza4lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_reduced.shape"
      ],
      "metadata": {
        "id": "giytKb3Ia6_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([train_df, df_reduced], axis = 1)\n",
        "print(merged_df.shape)\n",
        "#cut_off = 20\n",
        "\n",
        "# Display the merged DataFrame\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    merged_df.to_excel(writer, sheet_name='merged_data', index=False)\n",
        "\n",
        "ss_final_df = merged_df[merged_df['Class'] != -1].reset_index(drop=True)\n",
        "column_to_move = ss_final_df.pop('Class')  # Remove the column and store it\n",
        "ss_final_df.insert(len(ss_final_df.columns), 'Class', column_to_move)\n",
        "\n",
        "# Take first and last data and find the average for the oral bioavailability\n",
        "# Not required now\n",
        "def average_bioavailability(value):\n",
        "    if 'to' in value:\n",
        "        min_value, max_value = map(str, value.split('to'))\n",
        "        average_value = ((float(min_value) + float(max_value)) / 2)\n",
        "        return average_value\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "ss_final_df['Oral Bioavailability'] = ss_final_df['Oral Bioavailability'].apply(average_bioavailability)"
      ],
      "metadata": {
        "id": "t9EbCfxSa7ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ss_final_df.shape"
      ],
      "metadata": {
        "id": "r1D81Aj5a-Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert the 'Oral Bioavailability' column to numeric, coercing errors to NaN\n",
        "ss_final_df['Oral Bioavailability'] = pd.to_numeric(ss_final_df['Oral Bioavailability'], errors='coerce')\n",
        "\n",
        "# Handle NaN values - fill them with 0\n",
        "ss_final_df['Oral Bioavailability'] = ss_final_df['Oral Bioavailability'].fillna(0)\n",
        "\n",
        "# Define bioavailability ranges\n",
        "bins = [0, 1, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "labels = ['0', '1-10', '11-20', '21-30', '31-40', '41-50', '51-60', '61-70', '71-80', '81-90', '91-100']\n",
        "\n",
        "# Create a new column for the bioavailability ranges\n",
        "ss_final_df['Bioavailability Range'] = pd.cut(ss_final_df['Oral Bioavailability'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Count the number of compounds in each range\n",
        "range_counts = ss_final_df['Bioavailability Range'].value_counts().sort_index()\n",
        "\n",
        "# Prepare the data for plotting\n",
        "plot_data = pd.DataFrame({'Bioavailability Range': range_counts.index, 'Count': range_counts.values})\n",
        "\n",
        "# Define custom colors for low and high ranges\n",
        "colors = ['#B2B2B2'] * 3 + ['#80CBC4'] * (len(plot_data) - 3)  # Light gray for low, teal green for high\n",
        "\n",
        "# Set the context to increase font size\n",
        "sns.set_context(\"talk\", font_scale=1.4)  # \"talk\" context with larger font scale\n",
        "\n",
        "# Plot the distribution\n",
        "plt.figure(figsize=(10, 8))  # Reduce width of the plot\n",
        "ax = sns.barplot(x='Bioavailability Range', y='Count', data=plot_data, palette=colors, hue=None, legend=False)\n",
        "\n",
        "# Add a vertical line to distinguish low and high ranges\n",
        "# Find the index corresponding to the 20% range\n",
        "threshold_index = plot_data[plot_data['Bioavailability Range'] == '21-30'].index[0]\n",
        "ax.axvline(x=threshold_index - 0.5, color='black', linestyle='--', linewidth=2, label='Low/High')\n",
        "\n",
        "# Adjust the bar width\n",
        "for patch in ax.patches:\n",
        "    # Reduce the width of each bar (default is 0.8, adjust as needed)\n",
        "    patch.set_width(0.5)\n",
        "\n",
        "plt.xlabel('Bioavailability Range (%)', fontsize=24)\n",
        "plt.ylabel('Number of Compounds', fontsize=24)\n",
        "plt.xticks(rotation=45, fontsize=24)\n",
        "plt.yticks(fontsize=24)\n",
        "plt.legend(fontsize=18)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig('/content/drive/MyDrive/HOB/Rerun/distribution_bio.eps', format='eps')\n",
        "plt.savefig('/content/drive/MyDrive/HOB/Rerun/distribution_bio.png', format='png')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UkF8N-P5a-uw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#input_df['Class'] = pd.to_numeric(input_df['Oral Bioavailability'], errors='coerce').apply(lambda x: 'high' if x > cut_off else 'low')\n",
        "ss_final_df.drop('Oral Bioavailability', axis=1, inplace=True)\n",
        "ss_final_df.drop('Pharmacological Class', axis=1, inplace=True)\n",
        "ss_final_df.drop('Bioavailability Range', axis=1, inplace=True)\n",
        "#merged_df.drop('MolMR', axis=1, inplace=True)\n",
        "\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    ss_final_df.to_excel(writer, sheet_name='ss_final_data', index=False)\n",
        "\n",
        "final_df = ss_final_df.copy()\n",
        "\n",
        "final_df.drop('Structure (SMILES)', axis=1, inplace=True)\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    final_df.to_excel(writer, sheet_name='final_data', index=False)\n",
        "\n",
        "separated_df = merged_df[merged_df['Class'] == -1].reset_index(drop=True)\n",
        "column_to_move = separated_df.pop('Class')  # Remove the column and store it\n",
        "separated_df.insert(len(separated_df.columns), 'Class', column_to_move)\n",
        "\n",
        "# Display the merged DataFrame\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    separated_df.to_excel(writer, sheet_name='separated_data', index=False)\n",
        "\n",
        "print(final_df.shape)"
      ],
      "metadata": {
        "id": "P51vsoMdbB5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_descriptors = df_reduced.columns\n",
        "test_smiles_string = test_df[\"Structure (SMILES)\"]\n",
        "\n",
        "test_data = [compute_topological_features(smiles, selected_descriptors) for smiles in test_smiles_string]\n",
        "test_descriptors_df = pd.DataFrame(test_data, columns = selected_descriptors)\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    test_descriptors_df.to_excel(writer, sheet_name='test_descriptors', index=False)\n",
        "\n",
        "test_merged_df = pd.concat([test_df, test_descriptors_df], axis = 1)\n",
        "print(test_merged_df.shape)\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    test_merged_df.to_excel(writer, sheet_name='test_merged_data', index=False)\n",
        "\n",
        "test_merged_df.drop('Structure (SMILES)', axis=1, inplace=True)\n",
        "test_merged_df.drop('Oral Bioavailability', axis =1, inplace =True)\n",
        "test_merged_df.drop('Pharmacological Class', axis=1, inplace=True)\n",
        "column_to_move = test_merged_df.pop('Class')  # Remove the column and store it\n",
        "test_merged_df.insert(len(test_merged_df.columns), 'Class', column_to_move)\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    test_merged_df.to_excel(writer, sheet_name='test_final_data', index=False)\n"
      ],
      "metadata": {
        "id": "Gn3VylGibCgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_smiles = ss_final_df['Structure (SMILES)']\n",
        "#test_smiles_string\n",
        "def tanimoto_coefficient(fp1, fp2):\n",
        "    return DataStructs.TanimotoSimilarity(fp1, fp2)\n",
        "train_fps = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smiles), 2) for smiles in train_smiles]\n",
        "test_fps_1 = [AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(smiles), 2) for smiles in test_smiles_string]\n",
        "def max_tanimoto_similarity(test_fps, train_fps):\n",
        "    similarities = []\n",
        "    for test_fp in test_fps:\n",
        "        max_similarity = max(tanimoto_coefficient(test_fp, train_fp) for train_fp in train_fps)\n",
        "        similarities.append(max_similarity)\n",
        "    return similarities\n",
        "\n",
        "# Compute similarities\n",
        "similarities_test_1 = max_tanimoto_similarity(test_fps_1, train_fps)\n",
        "\n",
        "average_similarity_test_1 = np.mean(similarities_test_1)\n"
      ],
      "metadata": {
        "id": "wXB8bv0GbFd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for box plot\n",
        "data = [similarities_test_1]\n",
        "labels = ['Test Set']\n",
        "\n",
        "# Create box plot with lighter, more transparent boxes\n",
        "plt.figure(figsize=(12, 8))\n",
        "box = plt.boxplot(data, labels=labels, vert=False, patch_artist=True,\n",
        "                  boxprops=dict(facecolor='lightblue', alpha=0.4),  # Lighter blue with transparency\n",
        "                  whiskerprops=dict(color='lightblue', alpha=0.6),  # Lighter whisker color with transparency\n",
        "                  capprops=dict(color='lightblue', alpha=0.6),      # Lighter cap color with transparency\n",
        "                  medianprops=dict(color='lightblue'))              # Lighter median line color\n",
        "\n",
        "# Overlay individual points\n",
        "for i, points in enumerate(data):\n",
        "    plt.scatter(points, [i + 1] * len(points), color='black', alpha=0.6, label='Individual Points' if i == 0 else \"\")\n",
        "\n",
        "# Add horizontal lines and labels\n",
        "plt.xlabel('Tanimoto Similarity')\n",
        "#plt.title('Distribution of Tanimoto Similarity Scores')\n",
        "plt.grid(True)\n",
        "\n",
        "# Add legend\n",
        "plt.legend(loc='best')\n",
        "\n",
        "# Save as PDF first\n",
        "plt.savefig('/content/drive/MyDrive/HOB/Rerun/tanimoto.png', format='png')\n",
        "plt.savefig('/content/drive/MyDrive/HOB/Rerun/tanimoto.eps', format='eps')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ITed8MrvbHGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset preprocessing\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "def remove_lower_var_col(data, var_thresh):\n",
        "    drug_names = data.iloc[:, 0]\n",
        "    X = data.iloc[:, 1:-1]\n",
        "    y = data.iloc[:, -1]\n",
        "    selector = VarianceThreshold(var_thresh)\n",
        "    X.replace([np.inf, -np.inf], np.finfo(np.float64).max, inplace=True)\n",
        "    X_selected = selector.fit_transform(X)\n",
        "    selected_indices = selector.get_support(indices=True)\n",
        "    selected_features = X.columns[selected_indices]\n",
        "    selected_df = pd.DataFrame(X_selected, columns=selected_features)\n",
        "    selected_df.insert(0, 'Drug Name', drug_names)\n",
        "    selected_df['Class'] = y\n",
        "    return selected_df\n",
        "\n",
        "#selected_df = remove_lower_var_col(final_df, 0.001)\n",
        "#print(selected_df.shape)\n",
        "#with pd.ExcelWriter('D:\\Dataset_koyel\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        " #   selected_df.to_excel(writer, sheet_name='var_removed', index=False)\n",
        "\n",
        "\n",
        "def preprocess_classification(X):\n",
        "    X.replace([np.inf, -np.inf], np.finfo(np.float64).max, inplace=True)\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "    scaler = MinMaxScaler()\n",
        "    #scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X_imputed)\n",
        "    return X_scaled\n",
        "\n",
        "train_pre = preprocess_classification(final_df.iloc[:, 1:-1])\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    pd.DataFrame(train_pre).to_excel(writer, sheet_name='input_classifier', index=False)\n",
        "\n",
        "print(train_pre.shape)"
      ],
      "metadata": {
        "id": "wC0NogsFbJBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pre = preprocess_classification(test_merged_df.iloc[:, 1:-1])\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "    pd.DataFrame(test_pre).to_excel(writer, sheet_name='test_classifier', index=False)\n",
        "\n",
        "print(test_pre.shape)"
      ],
      "metadata": {
        "id": "gblh5e8PbKx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the final data size\", train_pre.shape)\n",
        "y_binary = final_df['Class']\n",
        "class_distribution = final_df['Class'].value_counts()\n",
        "print(class_distribution)"
      ],
      "metadata": {
        "id": "k2T2LzAhbMfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "id": "n2nmcfxcbOGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the final data size\", test_pre.shape)\n",
        "yt_binary = test_merged_df['Class']\n",
        "class_distribution = test_merged_df['Class'].value_counts()\n",
        "print(class_distribution)"
      ],
      "metadata": {
        "id": "VPp596NCbPn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "from chembl_webresource_client.new_client import new_client\n",
        "import pubchempy as pcp\n",
        "\n",
        "# Initialize ChEMBL client\n",
        "molecule = new_client.molecule\n",
        "\n",
        "# Function to normalize drug names by removing special characters\n",
        "def normalize_drug_name(name):\n",
        "    return re.sub(r'[^a-zA-Z0-9]', '', name).lower()\n",
        "\n",
        "# Function to parse DrugBank XML file and extract necessary information\n",
        "def parse_drugbank_xml(file_path):\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    drug_data = []\n",
        "\n",
        "    for drug in root.findall(\"{http://www.drugbank.ca}drug\"):\n",
        "        drug_name = drug.find(\"{http://www.drugbank.ca}name\").text\n",
        "        normalized_name = normalize_drug_name(drug_name)\n",
        "\n",
        "        calculated_properties = drug.find(\"{http://www.drugbank.ca}calculated-properties\")\n",
        "        atc_codes = drug.find(\"{http://www.drugbank.ca}atc-codes\")\n",
        "\n",
        "        smiles_text = None\n",
        "        atc_codes_list = []\n",
        "\n",
        "        if calculated_properties is not None:\n",
        "            for property in calculated_properties.findall(\"{http://www.drugbank.ca}property\"):\n",
        "                kind = property.find(\"{http://www.drugbank.ca}kind\").text\n",
        "                if kind == \"SMILES\":\n",
        "                    smiles_text = property.find(\"{http://www.drugbank.ca}value\").text\n",
        "                    break\n",
        "\n",
        "        if atc_codes is not None:\n",
        "            for atc_code in atc_codes.findall(\"{http://www.drugbank.ca}atc-code\"):\n",
        "                atc_codes_list.append(atc_code.get(\"code\"))\n",
        "\n",
        "        drug_data.append({\n",
        "            \"Drug_Name\": drug_name,\n",
        "            \"Normalized_Name\": normalized_name,\n",
        "            \"SMILES\": smiles_text,\n",
        "            \"ATC_Codes\": atc_codes_list if atc_codes_list else None\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(drug_data)\n",
        "\n",
        "# Load DrugBank data from XML file\n",
        "drugbank_df = parse_drugbank_xml(r'C:\\Users\\Prof.Ashish Ghosh\\Desktop\\Dataset\\Drug\\full database.xml')\n",
        "\n",
        "# Example list of drug names with possible variations\n",
        "drug_names = test_df['Drug Name']\n",
        "\n",
        "# Function to get SMILES from DrugBank using normalized drug name\n",
        "def get_smiles_from_drugbank(drug_name):\n",
        "    normalized_name = normalize_drug_name(drug_name)\n",
        "    try:\n",
        "        row = drugbank_df.loc[drugbank_df['Normalized_Name'] == normalized_name]\n",
        "        if not row.empty and pd.notna(row.iloc[0]['SMILES']):\n",
        "            return row.iloc[0]['SMILES']\n",
        "        else:\n",
        "            print(f\"No SMILES found for {drug_name} in DrugBank\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving SMILES for {drug_name} from DrugBank: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to get ATC codes from DrugBank using normalized drug name\n",
        "def get_atc_code_from_drugbank(drug_name):\n",
        "    normalized_name = normalize_drug_name(drug_name)\n",
        "    try:\n",
        "        row = drugbank_df.loc[drugbank_df['Normalized_Name'] == normalized_name]\n",
        "        if not row.empty and pd.notna(row.iloc[0]['ATC_Codes']):\n",
        "            return row.iloc[0]['ATC_Codes']\n",
        "        else:\n",
        "            print(f\"No ATC codes found for {drug_name} in DrugBank\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving ATC codes for {drug_name} from DrugBank: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to get SMILES from PubChem using drug name\n",
        "def get_smiles_from_pubchem(drug_name):\n",
        "    try:\n",
        "        compounds = pcp.get_compounds(drug_name, 'name')\n",
        "        if compounds:\n",
        "            return compounds[0].canonical_smiles\n",
        "        else:\n",
        "            print(f\"No SMILES found for {drug_name} in PubChem\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving SMILES for {drug_name} from PubChem: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to get SMILES from ChEMBL using drug name\n",
        "def get_smiles_from_chembl(drug_name):\n",
        "    try:\n",
        "        res = molecule.filter(pref_name__iexact=drug_name).only(['molecule_structures'])\n",
        "        if res and res[0]['molecule_structures']:\n",
        "            return res[0]['molecule_structures']['canonical_smiles']\n",
        "        else:\n",
        "            print(f\"No SMILES found for {drug_name} in ChEMBL\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving SMILES for {drug_name} from ChEMBL: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to get ATC codes from ChEMBL using drug name\n",
        "def get_atc_code_from_chembl(drug_name):\n",
        "    try:\n",
        "        res = molecule.filter(pref_name__iexact=drug_name).only(['atc_classifications'])\n",
        "        if res and res[0]['atc_classifications']:\n",
        "            return res[0]['atc_classifications']\n",
        "        else:\n",
        "            print(f\"No ATC codes found for {drug_name} in ChEMBL\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving ATC codes for {drug_name} from ChEMBL: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create a DataFrame to store results\n",
        "results = []\n",
        "\n",
        "# Function to handle variations in drug names\n",
        "def get_drug_info(drug_name_variations):\n",
        "    for name in drug_name_variations:\n",
        "        # Check DrugBank\n",
        "        smiles = get_smiles_from_drugbank(name)\n",
        "        if smiles:\n",
        "            atc_codes = get_atc_code_from_drugbank(name)\n",
        "            return {'Drug_Name': name, 'SMILES': smiles, 'ATC_Codes': atc_codes}\n",
        "\n",
        "        # Check PubChem\n",
        "        smiles = get_smiles_from_pubchem(name)\n",
        "        if smiles:\n",
        "            atc_codes = get_atc_code_from_chembl(name)  # PubChem does not provide ATC codes\n",
        "            return {'Drug_Name': name, 'SMILES': smiles, 'ATC_Codes': atc_codes}\n",
        "\n",
        "        # Check ChEMBL\n",
        "        smiles = get_smiles_from_chembl(name)\n",
        "        if smiles:\n",
        "            atc_codes = get_atc_code_from_chembl(name)\n",
        "            return {'Drug_Name': name, 'SMILES': smiles, 'ATC_Codes': atc_codes}\n",
        "\n",
        "    return {'Drug_Name': drug_name_variations[0], 'SMILES': None, 'ATC_Codes': None}\n",
        "\n",
        "for drug_name in drug_names:\n",
        "    variations = [drug_name, normalize_drug_name(drug_name)]\n",
        "    results.append(get_drug_info(variations))\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Save results to CSV file\n",
        "df_results.to_csv(r'D:\\Dataset_koyel\\test_drug_smiles_atc_combined.csv', index=False)\n",
        "\n",
        "# Display the results\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "id": "ojFfuUyzbRUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ATC code frequency matrix\n",
        "\n",
        "atc_train = pd.read_excel('/content/drive/MyDrive/HOB/drug_atc.xlsx', sheet_name='train_final')\n",
        "atc_test = pd.read_excel('/content/drive/MyDrive/HOB/drug_atc.xlsx', sheet_name='test')\n",
        "#print(atc_train.columns)\n",
        "#print(atc_test.columns)\n",
        "\n",
        "atc_train_filled = atc_train[['Drug Name', 'ATC_Codes']].fillna('0').apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "atc_test_filled = atc_test[['Drug Name', 'ATC_Codes']].fillna('0').apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "atc_codes = pd.concat([atc_train_filled, atc_test_filled], axis=0).reset_index(drop=True)\n",
        "#atc_codes = atc_codes.to_frame(name='ATC_Codes')"
      ],
      "metadata": {
        "id": "FPgSBPz5bTzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split ATC codes\n",
        "def split_atc_codes(atc_codes):\n",
        "    if atc_codes == '0':\n",
        "        return ['0']\n",
        "    atc_codes = atc_codes.strip()\n",
        "    parts = []\n",
        "    for code in atc_codes.split(', '):\n",
        "        code = code.strip()\n",
        "        if len(code) >= 1:\n",
        "            parts.append(code[0])  # Single char\n",
        "        if len(code) >= 3:\n",
        "            parts.append(code[:3])  # Single char and two digits\n",
        "        if len(code) >= 4:\n",
        "            parts.append(code[:4])  # Single char, two digits, single char\n",
        "        if len(code) >= 5:\n",
        "            parts.append(code[:5])  # Single char, two digits, two chars\n",
        "        parts.append(code)  # Entire string\n",
        "    return parts\n",
        "\n",
        "# Apply split function and get unique ATC code parts\n",
        "all_atc_parts = atc_codes['ATC_Codes'].apply(split_atc_codes)\n",
        "unique_atc_parts = set(part for sublist in all_atc_parts for part in sublist)\n",
        "unique_atc_parts = sorted(unique_atc_parts)\n",
        "\n",
        "unique_atc_parts = [code for code in unique_atc_parts if code != '0']\n",
        "#unique_atc_parts\n",
        "\n",
        "atc_matrix_train = pd.DataFrame(0, index = atc_train['Drug Name'], columns = unique_atc_parts)\n",
        "atc_matrix_test = pd.DataFrame(0, index = atc_test['Drug Name'], columns = unique_atc_parts)"
      ],
      "metadata": {
        "id": "LQyge_vTbVSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming atc_test_filled is a DataFrame or converting if it's not\n",
        "atc_matrix_train = pd.DataFrame(0, index=atc_train['Drug Name'], columns=unique_atc_parts)\n",
        "\n",
        "# Assuming atc_train_filled is a DataFrame or converting if it's not\n",
        "if not isinstance(atc_train_filled, pd.DataFrame):\n",
        "    atc_train_filled = pd.DataFrame(atc_train_filled)\n",
        "\n",
        "# Now iterate over rows in the DataFrame\n",
        "for i, row in atc_train_filled.iterrows():\n",
        "    atc_codes = split_atc_codes(row['ATC_Codes'])\n",
        "   # print(atc_codes)\n",
        "    for code in atc_codes:\n",
        "        if code in unique_atc_parts:\n",
        "            atc_matrix_train.at[row['Drug Name'], code] += 1\n",
        "\n",
        "# Fill NaN or missing values with 0\n",
        "atc_matrix_train.fillna(0, inplace=True)\n",
        "\n",
        "# Display the resulting matrix\n",
        "#print(atc_matrix_train)\n",
        "print(atc_matrix_train.shape)"
      ],
      "metadata": {
        "id": "snYrciMMbV0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "atc_matrix_test = pd.DataFrame(0, index=atc_test['Drug Name'], columns=unique_atc_parts)\n",
        "\n",
        "# Assuming atc_test_filled is a DataFrame or converting if it's not\n",
        "if not isinstance(atc_test_filled, pd.DataFrame):\n",
        "    atc_test_filled = pd.DataFrame(atc_test_filled)\n",
        "\n",
        "# Now iterate over rows in the DataFrame\n",
        "for i, row in atc_test_filled.iterrows():\n",
        "    atc_codes = split_atc_codes(row['ATC_Codes'])\n",
        "    #print(atc_codes)\n",
        "    for code in atc_codes:\n",
        "        if code in unique_atc_parts:\n",
        "            atc_matrix_test.at[row['Drug Name'], code] += 1\n",
        "\n",
        "# Fill NaN or missing values with 0\n",
        "atc_matrix_test.fillna(0, inplace=True)\n",
        "\n",
        "# Display the resulting matrix\n",
        "#print(atc_matrix_test)\n",
        "print(atc_matrix_test.shape)"
      ],
      "metadata": {
        "id": "WJmKRQPpbYr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_classification_atc(X):\n",
        "    X_imputed = imputer.fit_transform(X)\n",
        "    scaler = MinMaxScaler()\n",
        "    #scaler = RobustScaler()\n",
        "    X_scaled = scaler.fit_transform(X_imputed)\n",
        "    return X_scaled\n",
        "\n",
        "train_atc_norm = preprocess_classification(atc_matrix_train.iloc[:, 0:])\n",
        "test_atc_norm = preprocess_classification(atc_matrix_test.iloc[:, 0:])\n",
        "#with pd.ExcelWriter(r'D:\\Dataset_koyel\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "#    pd.DataFrame(train_pre).to_excel(writer, sheet_name='input_classifier', index=False)\n",
        "\n",
        "print(train_atc_norm.shape)\n",
        "print(test_atc_norm.shape)"
      ],
      "metadata": {
        "id": "ntJ_usl2baY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(train_atc_norm).to_csv('/content/drive/MyDrive/HOB/Rerun/train_atc_norm.csv', index=False)\n",
        "pd.DataFrame(test_atc_norm).to_csv('/content/drive/MyDrive/HOB/Rerun/test_atc_norm.csv', index=False)"
      ],
      "metadata": {
        "id": "PX091rmD0Drz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_merged_array = np.concatenate((train_pre, train_atc_norm), axis=1)\n",
        "test_merged_array = np.concatenate((test_pre, test_atc_norm), axis=1)"
      ],
      "metadata": {
        "id": "1jq5Wqm1bb_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pre.shape"
      ],
      "metadata": {
        "id": "z7EXYSEMbeA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(train_merged_array).to_csv('/content/drive/MyDrive/HOB/Rerun/train_merged_array.csv', index=False)\n",
        "pd.DataFrame(test_merged_array).to_csv('/content/drive/MyDrive/HOB/Rerun/test_merged_array.csv', index=False)"
      ],
      "metadata": {
        "id": "Fc5jqpDl0jX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter tuning for combined"
      ],
      "metadata": {
        "id": "k0aW6Ohdbho_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Declare the classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm = \"SAMME\"),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0)\n",
        "}\n",
        "\n",
        "# Set the parameters\n",
        "param_grids = {\n",
        "    \"Random Forest\": {\n",
        "        'n_estimators': np.linspace(100, 500, num=5, dtype=int),  # Number of trees\n",
        "        'min_samples_leaf': np.linspace(1, 20, num=5, dtype=int)  # Minimum samples per leaf\n",
        "    },\n",
        "    \"Support Vector Machine\": {\n",
        "        \"C\": np.geomspace(0.03125, 32768, num=5),  # Regularization parameter\n",
        "        'gamma': np.geomspace(0.00003051757, 16, num=5),  # Kernel coefficient\n",
        "        'kernel': ['rbf', 'linear', 'poly', 'sigmoid']  # Kernel type\n",
        "    },\n",
        "    \"K-Nearest Neighbors\": {\n",
        "        \"n_neighbors\": np.linspace(3, 30, num=5, dtype=int)  # Number of neighbors\n",
        "    },\n",
        "    \"Decision Tree Classifier\": {\n",
        "        \"max_depth\": np.linspace(10, 40, num=5, dtype=int),  # Maximum tree depth\n",
        "        \"min_samples_split\": np.linspace(2, 20, num=5, dtype=int),  # Minimum samples per split\n",
        "        \"min_samples_leaf\": np.linspace(1, 20, num=5, dtype=int)  # Minimum samples per leaf\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        \"C\": np.linspace(0.1, 10, num=5),  # Regularization parameter\n",
        "        \"solver\": ['liblinear', 'saga']  # Solver algorithm\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        'n_estimators': np.linspace(40, 70, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.05, 0.2, num=5),  # Learning rate\n",
        "        'max_depth': np.linspace(4, 8, num=5, dtype=int)  # Maximum tree depth\n",
        "    },\n",
        "    \"Naive Bayes\": {},  # No parameters to tune for GaussianNB\n",
        "    \"AdaBoost Classifier\": {\n",
        "        'n_estimators': np.linspace(50, 300, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.01, 1.0, num=5)  # Learning rate\n",
        "    },\n",
        "    \"Extreme Gradient Boosting\": {\n",
        "        'n_estimators': np.linspace(100, 500, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.01, 0.2, num=5),  # Learning rate\n",
        "        'max_depth': np.linspace(3, 10, num=5, dtype=int),  # Maximum tree depth\n",
        "        'subsample': np.linspace(0.5, 1.0, num=5),  # Fraction of samples used per tree\n",
        "        'colsample_bytree': np.linspace(0.5, 1.0, num=5)  # Fraction of features used per tree\n",
        "    },\n",
        "    \"CatBoost Classifier\": {\n",
        "        'iterations': np.linspace(100, 500, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.001, 0.1, num=5),  # Learning rate\n",
        "        'depth': np.linspace(1, 10, num=5, dtype=int)  # Maximum tree depth\n",
        "    }\n",
        "}\n",
        "\n",
        "best_params_dict = {} # Dictionary to hold the best parameter settings\n",
        "\n",
        "results = {\n",
        "    \"Classifier\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"AUC\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": [],\n",
        "    \"F1 score\" : [],\n",
        "    \"Kappa\": []\n",
        "}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    param_grid = param_grids.get(name, {})\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(clf, param_grid, cv=cv, scoring='accuracy')\n",
        "    grid_search.fit(train_merged_array, y_binary)\n",
        "    #print(grid_search)\n",
        "\n",
        "    print(f\"Results for {name}:\")\n",
        "    cv_results = grid_search.cv_results_\n",
        "    with open(\"/content/drive/MyDrive/HOB/Rerun/grid_search_results.txt\", \"a+\") as f:\n",
        "        f.write(f\"The classification algorithm is: {name} \\n\")\n",
        "        for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
        "            f.write(f\"Mean accuracy: {mean_score}, Params: {params}\\n\")\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    #print(best_params)\n",
        "    with open(\"/content/drive/MyDrive/HOB/Rerun/grid_search_results.txt\", \"a+\") as f:\n",
        "        f.write(\"Best Parameters:\\n\")\n",
        "        for key, value in best_params.items():\n",
        "            f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "    best_params_dict[name] = best_params\n",
        "    final_clf = clf.set_params(**best_params)\n",
        "    #print(final_clf)\n",
        "\n",
        "    #cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(final_clf, train_merged_array, y_binary, cv=cv, scoring='accuracy')\n",
        "    #print(scores)\n",
        "\n",
        "    auc_scores = cross_val_score(final_clf, train_merged_array, y_binary, cv=cv, scoring='roc_auc')\n",
        "\n",
        "    bacc_scores = cross_val_score(final_clf, train_merged_array, y_binary, cv=cv, scoring='balanced_accuracy')\n",
        "\n",
        "    recall_scores = cross_val_score(final_clf, train_merged_array, y_binary, cv=cv, scoring='recall')\n",
        "\n",
        "    precision_scores = cross_val_score(final_clf, train_merged_array, y_binary, cv=cv, scoring='precision')\n",
        "\n",
        "    f1_scores = cross_val_score(final_clf, train_merged_array, y_binary, cv=cv, scoring='f1')\n",
        "\n",
        "    kappa_scores = []\n",
        "    for train_index, test_index in cv.split(train_merged_array, y_binary):\n",
        "        X_train, X_test = train_merged_array[train_index], train_merged_array[test_index]\n",
        "        y_train, y_test = y_binary[train_index], y_binary[test_index]\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        kappa = cohen_kappa_score(y_test, y_pred)\n",
        "        kappa_scores.append(kappa)\n",
        "\n",
        "    results[\"Classifier\"].append(name)\n",
        "    results[\"Accuracy\"].append(scores.mean())\n",
        "    results[\"AUC\"].append(auc_scores.mean())\n",
        "    results[\"Balanced Accuracy\"].append(bacc_scores.mean())\n",
        "    results[\"Recall\"].append(recall_scores.mean())\n",
        "    results[\"Precision\"].append(precision_scores.mean())\n",
        "    results[\"F1 score\"].append(f1_scores.mean())\n",
        "    results[\"Kappa\"].append(np.mean(kappa_scores))\n",
        "\n",
        "\n",
        "   # tprs = []\n",
        "   # aucs = []\n",
        "  #  mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "  #  fig, ax = plt.subplots()\n",
        "  #  for i, (train, test) in enumerate(cv.split(train_merged_array, y_binary)):\n",
        "  #      clf.fit(train_merged_array[train], y_binary[train])\n",
        "  #      probas_ = final_clf.predict_proba(train_merged_array[test])\n",
        "  #      fpr, tpr, thresholds = roc_curve(y_binary[test], probas_[:, 1])\n",
        "  #      tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
        "  #      tprs[-1][0] = 0.0\n",
        "   #     roc_auc = auc(fpr, tpr)\n",
        "  #      aucs.append(roc_auc)\n",
        "  #      ax.plot(fpr, tpr, lw=1, alpha=0.3, label=f'ROC fold {i+1} (AUC = {roc_auc:.2f})')\n",
        "\n",
        " #   ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
        "#    mean_tpr = np.mean(tprs, axis=0)\n",
        "#    mean_tpr[-1] = 1.0\n",
        "#    mean_auc = auc(mean_fpr, mean_tpr)\n",
        " #   std_auc = np.std(aucs)\n",
        "  #  ax.plot(mean_fpr, mean_tpr, color='b', label=f'Mean ROC (AUC = {mean_auc:.2f} $\\pm$ {std_auc:.2f})', lw=2, alpha=.8)\n",
        "#    ax.fill_between(mean_fpr, mean_tpr - std_auc, mean_tpr + std_auc, color='gray', alpha=.2)\n",
        " #   ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=f\"Receiver Operating Characteristic for {name}\")\n",
        " #   ax.legend(loc=\"lower right\")\n",
        " #   plt.show()\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "#results_df\n",
        "\n",
        "with pd.ExcelWriter('/content/drive/MyDrive/HOB/Rerun/grid_result.xlsx', engine='openpyxl', mode='w') as writer:\n",
        "    results_df.to_excel(writer, sheet_name='Results_grid', index=False)\n",
        "\n",
        "best_params_dict\n",
        "results_df\n"
      ],
      "metadata": {
        "id": "uazKvyNDbkm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params_dict"
      ],
      "metadata": {
        "id": "ca6W26VFbopW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on testing data using CFM after setting the parameters for multiple runs"
      ],
      "metadata": {
        "id": "QnOqHaYYbtAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, balanced_accuracy_score, recall_score,\n",
        "    precision_score, f1_score, cohen_kappa_score, roc_curve\n",
        ")\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=200),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=3.051757e-05, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=16),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=17, min_samples_leaf=1, min_samples_split=20),\n",
        "    \"Logistic Regression\": LogisticRegression(C=7.525, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.0875, max_depth=5, n_estimators=47),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.7525, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.625, learning_rate=0.105, max_depth=3, n_estimators=300, subsample=0.625),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=400, learning_rate=0.0505)\n",
        "}\n",
        "\n",
        "def evaluate_classifiers(train_data, train_labels, test_data, test_labels):\n",
        "    results = {\n",
        "        \"Classifier\": [],\n",
        "        \"Accuracy\": [],\n",
        "        \"AUC\": [],\n",
        "        \"Balanced Accuracy\": [],\n",
        "        \"Recall\": [],\n",
        "        \"Precision\": [],\n",
        "        \"F1 score\": [],\n",
        "        \"Kappa\": [],\n",
        "        \"Predicted Classes\": []\n",
        "    }\n",
        "    roc_data = []\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(train_data, train_labels)\n",
        "        y_pred = clf.predict(test_data)\n",
        "        y_prob = clf.predict_proba(test_data)[:, 1]\n",
        "\n",
        "        accuracy = accuracy_score(test_labels, y_pred)\n",
        "        auc_score = roc_auc_score(test_labels, y_prob)\n",
        "        balanced_acc = balanced_accuracy_score(test_labels, y_pred)\n",
        "        recall = recall_score(test_labels, y_pred)\n",
        "        precision = precision_score(test_labels, y_pred)\n",
        "        f1 = f1_score(test_labels, y_pred)\n",
        "        kappa = cohen_kappa_score(test_labels, y_pred)\n",
        "\n",
        "        results[\"Classifier\"].append(name)\n",
        "        results[\"Accuracy\"].append(accuracy)\n",
        "        results[\"AUC\"].append(auc_score)\n",
        "        results[\"Balanced Accuracy\"].append(balanced_acc)\n",
        "        results[\"Recall\"].append(recall)\n",
        "        results[\"Precision\"].append(precision)\n",
        "        results[\"F1 score\"].append(f1)\n",
        "        results[\"Kappa\"].append(kappa)\n",
        "        results[\"Predicted Classes\"].append(y_pred)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(test_labels, y_prob)\n",
        "        roc_data.append((name, fpr, tpr, auc_score))\n",
        "\n",
        "    return results, roc_data\n",
        "\n",
        "num_runs = 1\n",
        "aggregate_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"AUC\": np.zeros(len(classifiers)),\n",
        "    \"Balanced Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"Recall\": np.zeros(len(classifiers)),\n",
        "    \"Precision\": np.zeros(len(classifiers)),\n",
        "    \"F1 score\": np.zeros(len(classifiers)),\n",
        "    \"Kappa\": np.zeros(len(classifiers)),\n",
        "}\n",
        "\n",
        "best_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Best Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best AUC\": [-1] * len(classifiers),\n",
        "    \"Best Balanced Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best Recall\": [-1] * len(classifiers),\n",
        "    \"Best Precision\": [-1] * len(classifiers),\n",
        "    \"Best F1 score\": [-1] * len(classifiers),\n",
        "    \"Best Kappa\": [-1] * len(classifiers),\n",
        "    \"Best Predicted Classes\": [[] for _ in range(len(classifiers))]\n",
        "}\n",
        "\n",
        "# Running the evaluation multiple times\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "for run in range(num_runs):\n",
        "    results, roc_data = evaluate_classifiers(train_merged_array, y_binary, test_merged_array, yt_binary)\n",
        "    for i, classifier in enumerate(results[\"Classifier\"]):\n",
        "        # Update aggregate results\n",
        "        aggregate_results[\"Accuracy\"][i] += results[\"Accuracy\"][i]\n",
        "        aggregate_results[\"AUC\"][i] += results[\"AUC\"][i]\n",
        "        aggregate_results[\"Balanced Accuracy\"][i] += results[\"Balanced Accuracy\"][i]\n",
        "        aggregate_results[\"Recall\"][i] += results[\"Recall\"][i]\n",
        "        aggregate_results[\"Precision\"][i] += results[\"Precision\"][i]\n",
        "        aggregate_results[\"F1 score\"][i] += results[\"F1 score\"][i]\n",
        "        aggregate_results[\"Kappa\"][i] += results[\"Kappa\"][i]\n",
        "\n",
        "        # Update best results if the current run's accuracy is higher\n",
        "        if results[\"Accuracy\"][i] > best_results[\"Best Accuracy\"][i]:\n",
        "            best_results[\"Best Accuracy\"][i] = results[\"Accuracy\"][i]\n",
        "            best_results[\"Best AUC\"][i] = results[\"AUC\"][i]\n",
        "            best_results[\"Best Balanced Accuracy\"][i] = results[\"Balanced Accuracy\"][i]\n",
        "            best_results[\"Best Recall\"][i] = results[\"Recall\"][i]\n",
        "            best_results[\"Best Precision\"][i] = results[\"Precision\"][i]\n",
        "            best_results[\"Best F1 score\"][i] = results[\"F1 score\"][i]\n",
        "            best_results[\"Best Kappa\"][i] = results[\"Kappa\"][i]\n",
        "            best_results[\"Best Predicted Classes\"][i] = results[\"Predicted Classes\"][i]\n",
        "\n",
        "        # Append current ROC data for the classifier\n",
        "        all_roc_data[classifier].append(roc_data[i])\n",
        "\n",
        "# Calculate the average metrics for aggregate results\n",
        "for key in aggregate_results.keys():\n",
        "    if key != \"Classifier\":\n",
        "        aggregate_results[key] /= num_runs\n",
        "\n",
        "# Convert aggregate results and best results to DataFrames\n",
        "aggregate_results_df = pd.DataFrame(aggregate_results)\n",
        "best_results_df = pd.DataFrame({\n",
        "    \"Classifier\": best_results[\"Classifier\"],\n",
        "    \"Best Accuracy\": best_results[\"Best Accuracy\"],\n",
        "    \"Best AUC\": best_results[\"Best AUC\"],\n",
        "    \"Best Balanced Accuracy\": best_results[\"Best Balanced Accuracy\"],\n",
        "    \"Best Recall\": best_results[\"Best Recall\"],\n",
        "    \"Best Precision\": best_results[\"Best Precision\"],\n",
        "    \"Best F1 score\": best_results[\"Best F1 score\"],\n",
        "    \"Best Kappa\": best_results[\"Best Kappa\"]\n",
        "})\n",
        "\n",
        "# Save the aggregate and best results to an Excel file\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        aggregate_results_df.to_excel(writer, sheet_name='test_roc_cfm_avg', index=False)\n",
        "        best_results_df.to_excel(writer, sheet_name='test_roc_cfm_best', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Save the best predictions to a text file\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_cfm_best_predictions.txt', 'w') as f:\n",
        "    for classifier, preds in zip(best_results[\"Classifier\"], best_results[\"Best Predicted Classes\"]):\n",
        "        f.write(f\"Classifier: {classifier}\\n\")\n",
        "        f.write(\"Best Predicted Classes:\\n\")\n",
        "        for pred in preds:\n",
        "            f.write(f\"{pred}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Save the ROC data for later use\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_cfm.pkl', 'wb') as file:\n",
        "    pickle.dump(best_results, file)\n",
        "    pickle.dump(all_roc_data, file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yFty6W9jbqd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_results_df"
      ],
      "metadata": {
        "id": "4hJc5ojtbv-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggregate_results_df"
      ],
      "metadata": {
        "id": "_77qoXQtb136"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[1], roc[2], roc[3]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[3] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_cfm.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_cfm.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F85DQ3iJb35x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read from pickle file if required. else ignore\n",
        "#with open(r'D:\\\\Dataset_koyel\\\\all_roc_data.pkl', 'rb') as file:\n",
        "#    all_roc_data = pickle.load(file)"
      ],
      "metadata": {
        "id": "q-JzlKeEb57p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on testing data using different sampling techniques after setting the parameters multiple runs"
      ],
      "metadata": {
        "id": "ZG8YAku-b8gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, balanced_accuracy_score, recall_score,\n",
        "    precision_score, f1_score, cohen_kappa_score, roc_curve\n",
        ")\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=200),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=3.051757e-05, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=16),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=17, min_samples_leaf=1, min_samples_split=20),\n",
        "    \"Logistic Regression\": LogisticRegression(C=7.525, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.0875, max_depth=5, n_estimators=47),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.7525, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.625, learning_rate=0.105, max_depth=3, n_estimators=300, subsample=0.625),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=400, learning_rate=0.0505)\n",
        "}\n",
        "# Apply Random Oversampling to the training data\n",
        "#ros = RandomOverSampler(random_state=42)\n",
        "#X_resampled, y_resampled = ros.fit_resample(train_pre, y_binary)\n",
        "#X_resampled, y_resampled = ros.fit_resample(train_merged_array, y_binary)\n",
        "\n",
        "#Random undersampling\n",
        "#rus = RandomUnderSampler(random_state=42)# fit predictor and target variable not a good option\n",
        "#X_resampled, y_resampled = rus.fit_resample(train_pre, y_binary)\n",
        "#X_resampled, y_resampled = rus.fit_resample(train_merged_array, y_binary)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "#X_resampled, y_resampled = smote.fit_resample(train_pre, y_binary)\n",
        "X_resampled, y_resampled = smote.fit_resample(train_merged_array, y_binary)\n",
        "\n",
        "# Ensure the resampled data is in DataFrame and Series format\n",
        "X_resampled = pd.DataFrame(X_resampled)\n",
        "y_resampled = pd.Series(y_resampled)\n",
        "\n",
        "def evaluate_classifiers(train_data, train_labels, test_data, test_labels):\n",
        "    results = {\n",
        "        \"Classifier\": [],\n",
        "        \"Accuracy\": [],\n",
        "        \"AUC\": [],\n",
        "        \"Balanced Accuracy\": [],\n",
        "        \"Recall\": [],\n",
        "        \"Precision\": [],\n",
        "        \"F1 score\": [],\n",
        "        \"Kappa\": [],\n",
        "        \"Predicted Classes\": []\n",
        "    }\n",
        "    roc_data = []\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(train_data, train_labels)\n",
        "        y_pred = clf.predict(test_data)\n",
        "        y_prob = clf.predict_proba(test_data)[:, 1]\n",
        "\n",
        "        accuracy = accuracy_score(test_labels, y_pred)\n",
        "        auc_score = roc_auc_score(test_labels, y_prob)\n",
        "        balanced_acc = balanced_accuracy_score(test_labels, y_pred)\n",
        "        recall = recall_score(test_labels, y_pred)\n",
        "        precision = precision_score(test_labels, y_pred)\n",
        "        f1 = f1_score(test_labels, y_pred)\n",
        "        kappa = cohen_kappa_score(test_labels, y_pred)\n",
        "\n",
        "        results[\"Classifier\"].append(name)\n",
        "        results[\"Accuracy\"].append(accuracy)\n",
        "        results[\"AUC\"].append(auc_score)\n",
        "        results[\"Balanced Accuracy\"].append(balanced_acc)\n",
        "        results[\"Recall\"].append(recall)\n",
        "        results[\"Precision\"].append(precision)\n",
        "        results[\"F1 score\"].append(f1)\n",
        "        results[\"Kappa\"].append(kappa)\n",
        "        results[\"Predicted Classes\"].append(y_pred)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(test_labels, y_prob)\n",
        "        roc_data.append((name, fpr, tpr, auc_score))\n",
        "\n",
        "    return results, roc_data\n",
        "\n",
        "num_runs = 10\n",
        "aggregate_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"AUC\": np.zeros(len(classifiers)),\n",
        "    \"Balanced Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"Recall\": np.zeros(len(classifiers)),\n",
        "    \"Precision\": np.zeros(len(classifiers)),\n",
        "    \"F1 score\": np.zeros(len(classifiers)),\n",
        "    \"Kappa\": np.zeros(len(classifiers)),\n",
        "}\n",
        "\n",
        "best_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Best Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best AUC\": [-1] * len(classifiers),\n",
        "    \"Best Balanced Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best Recall\": [-1] * len(classifiers),\n",
        "    \"Best Precision\": [-1] * len(classifiers),\n",
        "    \"Best F1 score\": [-1] * len(classifiers),\n",
        "    \"Best Kappa\": [-1] * len(classifiers),\n",
        "    \"Best Predicted Classes\": [[] for _ in range(len(classifiers))]\n",
        "}\n",
        "\n",
        "# Running the evaluation multiple times\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "for run in range(num_runs):\n",
        "    results, roc_data = evaluate_classifiers(X_resampled, y_resampled, test_merged_array, yt_binary)\n",
        "    for i, classifier in enumerate(results[\"Classifier\"]):\n",
        "        # Update aggregate results\n",
        "        aggregate_results[\"Accuracy\"][i] += results[\"Accuracy\"][i]\n",
        "        aggregate_results[\"AUC\"][i] += results[\"AUC\"][i]\n",
        "        aggregate_results[\"Balanced Accuracy\"][i] += results[\"Balanced Accuracy\"][i]\n",
        "        aggregate_results[\"Recall\"][i] += results[\"Recall\"][i]\n",
        "        aggregate_results[\"Precision\"][i] += results[\"Precision\"][i]\n",
        "        aggregate_results[\"F1 score\"][i] += results[\"F1 score\"][i]\n",
        "        aggregate_results[\"Kappa\"][i] += results[\"Kappa\"][i]\n",
        "\n",
        "        # Update best results if the current run's accuracy is higher\n",
        "        if results[\"Accuracy\"][i] > best_results[\"Best Accuracy\"][i]:\n",
        "            best_results[\"Best Accuracy\"][i] = results[\"Accuracy\"][i]\n",
        "            best_results[\"Best AUC\"][i] = results[\"AUC\"][i]\n",
        "            best_results[\"Best Balanced Accuracy\"][i] = results[\"Balanced Accuracy\"][i]\n",
        "            best_results[\"Best Recall\"][i] = results[\"Recall\"][i]\n",
        "            best_results[\"Best Precision\"][i] = results[\"Precision\"][i]\n",
        "            best_results[\"Best F1 score\"][i] = results[\"F1 score\"][i]\n",
        "            best_results[\"Best Kappa\"][i] = results[\"Kappa\"][i]\n",
        "            best_results[\"Best Predicted Classes\"][i] = results[\"Predicted Classes\"][i]\n",
        "\n",
        "        # Append current ROC data for the classifier\n",
        "        all_roc_data[classifier].append(roc_data[i])\n",
        "\n",
        "# Calculate the average metrics for aggregate results\n",
        "for key in aggregate_results.keys():\n",
        "    if key != \"Classifier\":\n",
        "        aggregate_results[key] /= num_runs\n",
        "\n",
        "# Convert aggregate results and best results to DataFrames\n",
        "aggregate_results_df = pd.DataFrame(aggregate_results)\n",
        "best_results_df = pd.DataFrame({\n",
        "    \"Classifier\": best_results[\"Classifier\"],\n",
        "    \"Best Accuracy\": best_results[\"Best Accuracy\"],\n",
        "    \"Best AUC\": best_results[\"Best AUC\"],\n",
        "    \"Best Balanced Accuracy\": best_results[\"Best Balanced Accuracy\"],\n",
        "    \"Best Recall\": best_results[\"Best Recall\"],\n",
        "    \"Best Precision\": best_results[\"Best Precision\"],\n",
        "    \"Best F1 score\": best_results[\"Best F1 score\"],\n",
        "    \"Best Kappa\": best_results[\"Best Kappa\"]\n",
        "})\n",
        "\n",
        "# Save the aggregate and best results to an Excel file\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        aggregate_results_df.to_excel(writer, sheet_name='test_roc_cfm_avg_smote', index=False)\n",
        "        best_results_df.to_excel(writer, sheet_name='test_roc_cfm_best_smote', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Save the best predictions to a text file\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_cfm_best_predictions_smote.txt', 'w') as f:\n",
        "    for classifier, preds in zip(best_results[\"Classifier\"], best_results[\"Best Predicted Classes\"]):\n",
        "        f.write(f\"Classifier: {classifier}\\n\")\n",
        "        f.write(\"Best Predicted Classes:\\n\")\n",
        "        for pred in preds:\n",
        "            f.write(f\"{pred}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Save the ROC data for later use\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_cfm_.pkl', 'wb') as file:\n",
        "    pickle.dump(best_results, file)\n",
        "    pickle.dump(all_roc_data, file)"
      ],
      "metadata": {
        "id": "Z2eBxjDmcBiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[1], roc[2], roc[3]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[3] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_cfm_smote.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_cfm_smote.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nbWhIg-EcGAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cross validation CFM\n"
      ],
      "metadata": {
        "id": "OhHHzjsmcJpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
        "from sklearn.metrics import cohen_kappa_score, roc_curve, auc, accuracy_score, recall_score, precision_score, f1_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import openpyxl\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=200),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=3.051757e-05, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=16),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=17, min_samples_leaf=1, min_samples_split=20),\n",
        "    \"Logistic Regression\": LogisticRegression(C=7.525, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.0875, max_depth=5, n_estimators=47),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.7525, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.625, learning_rate=0.105, max_depth=3, n_estimators=300, subsample=0.625),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=400, learning_rate=0.0505)\n",
        "}\n",
        "# Initialize results dictionary\n",
        "results = {\n",
        "    \"Classifier\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"AUC\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": [],\n",
        "    \"F1 score\": [],\n",
        "    \"Kappa\": []\n",
        "}\n",
        "\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "\n",
        "# Loop through classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=10)\n",
        "    accuracy_scores = []\n",
        "    auc_scores = []\n",
        "    bacc_scores = []\n",
        "    recall_scores = []\n",
        "    precision_scores = []\n",
        "    f1_scores = []\n",
        "    kappa_scores = []\n",
        "\n",
        "    for train_index, test_index in cv.split(train_merged_array, y_binary):\n",
        "        X_train, X_test = train_merged_array[train_index], train_merged_array[test_index]\n",
        "        y_train, y_test = y_binary[train_index], y_binary[test_index]\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
        "        bacc_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        kappa_scores.append(cohen_kappa_score(y_test, y_pred))\n",
        "\n",
        "        # ROC Curve data\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        all_roc_data[name].append((fpr, tpr, roc_auc))\n",
        "\n",
        "    results[\"Classifier\"].append(name)\n",
        "    results[\"Accuracy\"].append(np.mean(accuracy_scores))\n",
        "    results[\"AUC\"].append(np.mean(auc_scores))\n",
        "    results[\"Balanced Accuracy\"].append(np.mean(bacc_scores))\n",
        "    results[\"Recall\"].append(np.mean(recall_scores))\n",
        "    results[\"Precision\"].append(np.mean(precision_scores))\n",
        "    results[\"F1 score\"].append(np.mean(f1_scores))\n",
        "    results[\"Kappa\"].append(np.mean(kappa_scores))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to Excel\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\Dataset_koyel\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        results_df.to_excel(writer, sheet_name='Cv_cfm', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[0], roc[1], roc[2]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[2] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_cfm.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_cfm.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GL50ti1-cL2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=200),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=3.051757e-05, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=16),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=17, min_samples_leaf=1, min_samples_split=20),\n",
        "    \"Logistic Regression\": LogisticRegression(C=7.525, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.0875, max_depth=5, n_estimators=47),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.7525, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.625, learning_rate=0.105, max_depth=3, n_estimators=300, subsample=0.625),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=400, learning_rate=0.0505)\n",
        "}\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {\n",
        "    \"Classifier\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"AUC\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": [],\n",
        "    \"F1 score\": [],\n",
        "    \"Kappa\": []\n",
        "}\n",
        "\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "\n",
        "# Loop through classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=10)\n",
        "    accuracy_scores = []\n",
        "    auc_scores = []\n",
        "    bacc_scores = []\n",
        "    recall_scores = []\n",
        "    precision_scores = []\n",
        "    f1_scores = []\n",
        "    kappa_scores = []\n",
        "\n",
        "    for train_index, test_index in cv.split(train_merged_array, y_binary):\n",
        "        X_train, X_test = train_merged_array[train_index], train_merged_array[test_index]\n",
        "        y_train, y_test = y_binary[train_index], y_binary[test_index]\n",
        "\n",
        "        # Apply Random Oversampling to the training data\n",
        "        #ros = RandomOverSampler(random_state=42)\n",
        "        #X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "        #Random undersampling\n",
        "        #rus = RandomUnderSampler(random_state=42)# fit predictor and target variable not a good option\n",
        "        #X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "        smote = SMOTE(random_state=42)\n",
        "        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "        clf.fit(X_train_resampled, y_train_resampled)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
        "        bacc_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        kappa_scores.append(cohen_kappa_score(y_test, y_pred))\n",
        "\n",
        "        # ROC Curve data\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        all_roc_data[name].append((fpr, tpr, roc_auc))\n",
        "\n",
        "    results[\"Classifier\"].append(name)\n",
        "    results[\"Accuracy\"].append(np.mean(accuracy_scores))\n",
        "    results[\"AUC\"].append(np.mean(auc_scores))\n",
        "    results[\"Balanced Accuracy\"].append(np.mean(bacc_scores))\n",
        "    results[\"Recall\"].append(np.mean(recall_scores))\n",
        "    results[\"Precision\"].append(np.mean(precision_scores))\n",
        "    results[\"F1 score\"].append(np.mean(f1_scores))\n",
        "    results[\"Kappa\"].append(np.mean(kappa_scores))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to Excel\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\Dataset_koyel\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        results_df.to_excel(writer, sheet_name='Cv_cfm_smote', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[0], roc[1], roc[2]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[2] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize = 24)\n",
        "plt.ylabel('True Positive Rate', fontsize = 24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_cfm_smote.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_cfm_smote.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KlkI8-TIcNj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "parameters settings for FM"
      ],
      "metadata": {
        "id": "ZNFon4SjcdHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Declare the classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm = \"SAMME\"),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0)\n",
        "}\n",
        "\n",
        "# Set the parameters\n",
        "param_grids = {\n",
        "    \"Random Forest\": {\n",
        "        'n_estimators': np.linspace(100, 500, num=5, dtype=int),  # Number of trees\n",
        "        'min_samples_leaf': np.linspace(1, 20, num=5, dtype=int)  # Minimum samples per leaf\n",
        "    },\n",
        "    \"Support Vector Machine\": {\n",
        "        \"C\": np.geomspace(0.03125, 32768, num=5),  # Regularization parameter\n",
        "        'gamma': np.geomspace(0.00003051757, 16, num=5),  # Kernel coefficient\n",
        "        'kernel': ['rbf', 'linear', 'poly', 'sigmoid']  # Kernel type\n",
        "    },\n",
        "    \"K-Nearest Neighbors\": {\n",
        "        \"n_neighbors\": np.linspace(3, 30, num=5, dtype=int)  # Number of neighbors\n",
        "    },\n",
        "    \"Decision Tree Classifier\": {\n",
        "        \"max_depth\": np.linspace(10, 40, num=5, dtype=int),  # Maximum tree depth\n",
        "        \"min_samples_split\": np.linspace(2, 20, num=5, dtype=int),  # Minimum samples per split\n",
        "        \"min_samples_leaf\": np.linspace(1, 20, num=5, dtype=int)  # Minimum samples per leaf\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        \"C\": np.linspace(0.1, 10, num=5),  # Regularization parameter\n",
        "        \"solver\": ['liblinear', 'saga']  # Solver algorithm\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        'n_estimators': np.linspace(40, 70, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.05, 0.2, num=5),  # Learning rate\n",
        "        'max_depth': np.linspace(4, 8, num=5, dtype=int)  # Maximum tree depth\n",
        "    },\n",
        "    \"Naive Bayes\": {},  # No parameters to tune for GaussianNB\n",
        "    \"AdaBoost Classifier\": {\n",
        "        'n_estimators': np.linspace(50, 300, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.01, 1.0, num=5)  # Learning rate\n",
        "    },\n",
        "    \"Extreme Gradient Boosting\": {\n",
        "        'n_estimators': np.linspace(100, 500, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.01, 0.2, num=5),  # Learning rate\n",
        "        'max_depth': np.linspace(3, 10, num=5, dtype=int),  # Maximum tree depth\n",
        "        'subsample': np.linspace(0.5, 1.0, num=5),  # Fraction of samples used per tree\n",
        "        'colsample_bytree': np.linspace(0.5, 1.0, num=5)  # Fraction of features used per tree\n",
        "    },\n",
        "    \"CatBoost Classifier\": {\n",
        "        'iterations': np.linspace(100, 500, num=5, dtype=int),  # Number of boosting stages\n",
        "        'learning_rate': np.linspace(0.001, 0.1, num=5),  # Learning rate\n",
        "        'depth': np.linspace(1, 10, num=5, dtype=int)  # Maximum tree depth\n",
        "    }\n",
        "}\n",
        "\n",
        "best_params_dict = {} # Dictionary to hold the best parameter settings\n",
        "\n",
        "results = {\n",
        "    \"Classifier\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"AUC\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": [],\n",
        "    \"F1 score\" : [],\n",
        "    \"Kappa\": []\n",
        "}\n",
        "\n",
        "for name, clf in classifiers.items():\n",
        "    param_grid = param_grids.get(name, {})\n",
        "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    grid_search = GridSearchCV(clf, param_grid, cv=cv, scoring='accuracy')\n",
        "    grid_search.fit(train_pre, y_binary)\n",
        "    #print(grid_search)\n",
        "\n",
        "    print(f\"Results for {name}:\")\n",
        "    cv_results = grid_search.cv_results_\n",
        "    with open(r\"D:\\Dataset_koyel\\grid_search_results_fm.txt\", \"a+\") as f:\n",
        "        f.write(f\"The classification algorithm is: {name} \\n\")\n",
        "        for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
        "            f.write(f\"Mean accuracy: {mean_score}, Params: {params}\\n\")\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    #print(best_params)\n",
        "    with open(r\"D:\\Dataset_koyel\\grid_search_results_fm.txt\", \"a+\") as f:\n",
        "        f.write(\"Best Parameters:\\n\")\n",
        "        for key, value in best_params.items():\n",
        "            f.write(f\"{key}: {value}\\n\")\n",
        "\n",
        "    best_params_dict[name] = best_params\n",
        "    final_clf = clf.set_params(**best_params)\n",
        "    #print(final_clf)\n",
        "\n",
        "    #cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    scores = cross_val_score(final_clf, train_pre, y_binary, cv=cv, scoring='accuracy')\n",
        "    #print(scores)\n",
        "\n",
        "    auc_scores = cross_val_score(final_clf, train_pre, y_binary, cv=cv, scoring='roc_auc')\n",
        "\n",
        "    bacc_scores = cross_val_score(final_clf, train_pre, y_binary, cv=cv, scoring='balanced_accuracy')\n",
        "\n",
        "    recall_scores = cross_val_score(final_clf, train_pre, y_binary, cv=cv, scoring='recall')\n",
        "\n",
        "    precision_scores = cross_val_score(final_clf, train_pre, y_binary, cv=cv, scoring='precision')\n",
        "\n",
        "    f1_scores = cross_val_score(final_clf, train_pre, y_binary, cv=cv, scoring='f1')\n",
        "\n",
        "    kappa_scores = []\n",
        "    for train_index, test_index in cv.split(train_pre, y_binary):\n",
        "        X_train, X_test = train_pre[train_index], train_pre[test_index]\n",
        "        y_train, y_test = y_binary[train_index], y_binary[test_index]\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        kappa = cohen_kappa_score(y_test, y_pred)\n",
        "        kappa_scores.append(kappa)\n",
        "\n",
        "    results[\"Classifier\"].append(name)\n",
        "    results[\"Accuracy\"].append(scores.mean())\n",
        "    results[\"AUC\"].append(auc_scores.mean())\n",
        "    results[\"Balanced Accuracy\"].append(bacc_scores.mean())\n",
        "    results[\"Recall\"].append(recall_scores.mean())\n",
        "    results[\"Precision\"].append(precision_scores.mean())\n",
        "    results[\"F1 score\"].append(f1_scores.mean())\n",
        "    results[\"Kappa\"].append(np.mean(kappa_scores))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "#results_df\n",
        "\n",
        "with pd.ExcelWriter(r'D:\\Dataset_koyel\\grid_result_fm.xlsx', engine='openpyxl', mode='w') as writer:\n",
        "    results_df.to_excel(writer, sheet_name='Results_grid_fm', index=False)\n",
        "\n",
        "print(results_df)\n",
        "print(best_params_dict)"
      ],
      "metadata": {
        "id": "ZJGoLFxFcfof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on testing data using FM after setting the parameters for multiple runs"
      ],
      "metadata": {
        "id": "m_VUdq_Scn0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=400),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=0.022097083970515203, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=30),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=6),\n",
        "    \"Logistic Regression\": LogisticRegression(C=0.1, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.1625, max_depth=6, n_estimators=70),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.505, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.75, learning_rate=0.1525, max_depth=8, n_estimators=300, subsample=0.75),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=100, learning_rate=0.1)\n",
        "}\n",
        "\n",
        "def evaluate_classifiers(train_data, train_labels, test_data, test_labels):\n",
        "    results = {\n",
        "        \"Classifier\": [],\n",
        "        \"Accuracy\": [],\n",
        "        \"AUC\": [],\n",
        "        \"Balanced Accuracy\": [],\n",
        "        \"Recall\": [],\n",
        "        \"Precision\": [],\n",
        "        \"F1 score\": [],\n",
        "        \"Kappa\": [],\n",
        "        \"Predicted Classes\": []\n",
        "    }\n",
        "    roc_data = []\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(train_data, train_labels)\n",
        "        y_pred = clf.predict(test_data)\n",
        "        y_prob = clf.predict_proba(test_data)[:, 1]\n",
        "\n",
        "        accuracy = accuracy_score(test_labels, y_pred)\n",
        "        auc_score = roc_auc_score(test_labels, y_prob)\n",
        "        balanced_acc = balanced_accuracy_score(test_labels, y_pred)\n",
        "        recall = recall_score(test_labels, y_pred)\n",
        "        precision = precision_score(test_labels, y_pred)\n",
        "        f1 = f1_score(test_labels, y_pred)\n",
        "        kappa = cohen_kappa_score(test_labels, y_pred)\n",
        "\n",
        "        results[\"Classifier\"].append(name)\n",
        "        results[\"Accuracy\"].append(accuracy)\n",
        "        results[\"AUC\"].append(auc_score)\n",
        "        results[\"Balanced Accuracy\"].append(balanced_acc)\n",
        "        results[\"Recall\"].append(recall)\n",
        "        results[\"Precision\"].append(precision)\n",
        "        results[\"F1 score\"].append(f1)\n",
        "        results[\"Kappa\"].append(kappa)\n",
        "        results[\"Predicted Classes\"].append(y_pred)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(test_labels, y_prob)\n",
        "        roc_data.append((name, fpr, tpr, auc_score))\n",
        "\n",
        "    return results, roc_data\n",
        "\n",
        "num_runs = 10\n",
        "aggregate_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"AUC\": np.zeros(len(classifiers)),\n",
        "    \"Balanced Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"Recall\": np.zeros(len(classifiers)),\n",
        "    \"Precision\": np.zeros(len(classifiers)),\n",
        "    \"F1 score\": np.zeros(len(classifiers)),\n",
        "    \"Kappa\": np.zeros(len(classifiers)),\n",
        "}\n",
        "\n",
        "best_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Best Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best AUC\": [-1] * len(classifiers),\n",
        "    \"Best Balanced Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best Recall\": [-1] * len(classifiers),\n",
        "    \"Best Precision\": [-1] * len(classifiers),\n",
        "    \"Best F1 score\": [-1] * len(classifiers),\n",
        "    \"Best Kappa\": [-1] * len(classifiers),\n",
        "    \"Best Predicted Classes\": [[] for _ in range(len(classifiers))]\n",
        "}\n",
        "\n",
        "# Running the evaluation multiple times\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "for run in range(num_runs):\n",
        "    results, roc_data = evaluate_classifiers(train_pre, y_binary, test_pre, yt_binary)\n",
        "    for i, classifier in enumerate(results[\"Classifier\"]):\n",
        "        # Update aggregate results\n",
        "        aggregate_results[\"Accuracy\"][i] += results[\"Accuracy\"][i]\n",
        "        aggregate_results[\"AUC\"][i] += results[\"AUC\"][i]\n",
        "        aggregate_results[\"Balanced Accuracy\"][i] += results[\"Balanced Accuracy\"][i]\n",
        "        aggregate_results[\"Recall\"][i] += results[\"Recall\"][i]\n",
        "        aggregate_results[\"Precision\"][i] += results[\"Precision\"][i]\n",
        "        aggregate_results[\"F1 score\"][i] += results[\"F1 score\"][i]\n",
        "        aggregate_results[\"Kappa\"][i] += results[\"Kappa\"][i]\n",
        "\n",
        "        # Update best results if the current run's accuracy is higher\n",
        "        if results[\"Accuracy\"][i] > best_results[\"Best Accuracy\"][i]:\n",
        "            best_results[\"Best Accuracy\"][i] = results[\"Accuracy\"][i]\n",
        "            best_results[\"Best AUC\"][i] = results[\"AUC\"][i]\n",
        "            best_results[\"Best Balanced Accuracy\"][i] = results[\"Balanced Accuracy\"][i]\n",
        "            best_results[\"Best Recall\"][i] = results[\"Recall\"][i]\n",
        "            best_results[\"Best Precision\"][i] = results[\"Precision\"][i]\n",
        "            best_results[\"Best F1 score\"][i] = results[\"F1 score\"][i]\n",
        "            best_results[\"Best Kappa\"][i] = results[\"Kappa\"][i]\n",
        "            best_results[\"Best Predicted Classes\"][i] = results[\"Predicted Classes\"][i]\n",
        "\n",
        "        # Append current ROC data for the classifier\n",
        "        all_roc_data[classifier].append(roc_data[i])\n",
        "\n",
        "# Calculate the average metrics for aggregate results\n",
        "for key in aggregate_results.keys():\n",
        "    if key != \"Classifier\":\n",
        "        aggregate_results[key] /= num_runs\n",
        "\n",
        "# Convert aggregate results and best results to DataFrames\n",
        "aggregate_results_df = pd.DataFrame(aggregate_results)\n",
        "best_results_df = pd.DataFrame({\n",
        "    \"Classifier\": best_results[\"Classifier\"],\n",
        "    \"Best Accuracy\": best_results[\"Best Accuracy\"],\n",
        "    \"Best AUC\": best_results[\"Best AUC\"],\n",
        "    \"Best Balanced Accuracy\": best_results[\"Best Balanced Accuracy\"],\n",
        "    \"Best Recall\": best_results[\"Best Recall\"],\n",
        "    \"Best Precision\": best_results[\"Best Precision\"],\n",
        "    \"Best F1 score\": best_results[\"Best F1 score\"],\n",
        "    \"Best Kappa\": best_results[\"Best Kappa\"]\n",
        "})\n",
        "\n",
        "# Save the aggregate and best results to an Excel file\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        aggregate_results_df.to_excel(writer, sheet_name='test_roc_fm_avg', index=False)\n",
        "        best_results_df.to_excel(writer, sheet_name='test_roc_fm_best', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Save the best predictions to a text file\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_fm_best_predictions.txt', 'w') as f:\n",
        "    for classifier, preds in zip(best_results[\"Classifier\"], best_results[\"Best Predicted Classes\"]):\n",
        "        f.write(f\"Classifier: {classifier}\\n\")\n",
        "        f.write(\"Best Predicted Classes:\\n\")\n",
        "        for pred in preds:\n",
        "            f.write(f\"{pred}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Save the ROC data for later use\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_fm.pkl', 'wb') as file:\n",
        "    pickle.dump(best_results, file)\n",
        "    pickle.dump(all_roc_data, file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V5uhDyjkcizn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[1], roc[2], roc[3]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[3] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_fm.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_fm.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2VTNdbVmcsmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation on testing data using different sampling techniques after setting the parameters"
      ],
      "metadata": {
        "id": "FoZSPUPycwwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=400),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=0.022097083970515203, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=30),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=6),\n",
        "    \"Logistic Regression\": LogisticRegression(C=0.1, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.1625, max_depth=6, n_estimators=70),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.505, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.75, learning_rate=0.1525, max_depth=8, n_estimators=300, subsample=0.75),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=100, learning_rate=0.1)\n",
        "}\n",
        "# Apply Random Oversampling to the training data\n",
        "#ros = RandomOverSampler(random_state=42)\n",
        "#X_resampled, y_resampled = ros.fit_resample(train_pre, y_binary)\n",
        "\n",
        "\n",
        "#Random undersampling\n",
        "rus = RandomUnderSampler(random_state=42)# fit predictor and target variable not a good option\n",
        "X_resampled, y_resampled = rus.fit_resample(train_pre, y_binary)\n",
        "\n",
        "#smote = SMOTE(random_state=42)\n",
        "#X_resampled, y_resampled = smote.fit_resample(train_pre, y_binary)\n",
        "\n",
        "\n",
        "# Ensure the resampled data is in DataFrame and Series format\n",
        "X_resampled = pd.DataFrame(X_resampled)\n",
        "y_resampled = pd.Series(y_resampled)\n",
        "def evaluate_classifiers(train_data, train_labels, test_data, test_labels):\n",
        "    results = {\n",
        "        \"Classifier\": [],\n",
        "        \"Accuracy\": [],\n",
        "        \"AUC\": [],\n",
        "        \"Balanced Accuracy\": [],\n",
        "        \"Recall\": [],\n",
        "        \"Precision\": [],\n",
        "        \"F1 score\": [],\n",
        "        \"Kappa\": [],\n",
        "        \"Predicted Classes\": []\n",
        "    }\n",
        "    roc_data = []\n",
        "\n",
        "    for name, clf in classifiers.items():\n",
        "        clf.fit(train_data, train_labels)\n",
        "        y_pred = clf.predict(test_data)\n",
        "        y_prob = clf.predict_proba(test_data)[:, 1]\n",
        "\n",
        "        accuracy = accuracy_score(test_labels, y_pred)\n",
        "        auc_score = roc_auc_score(test_labels, y_prob)\n",
        "        balanced_acc = balanced_accuracy_score(test_labels, y_pred)\n",
        "        recall = recall_score(test_labels, y_pred)\n",
        "        precision = precision_score(test_labels, y_pred)\n",
        "        f1 = f1_score(test_labels, y_pred)\n",
        "        kappa = cohen_kappa_score(test_labels, y_pred)\n",
        "\n",
        "        results[\"Classifier\"].append(name)\n",
        "        results[\"Accuracy\"].append(accuracy)\n",
        "        results[\"AUC\"].append(auc_score)\n",
        "        results[\"Balanced Accuracy\"].append(balanced_acc)\n",
        "        results[\"Recall\"].append(recall)\n",
        "        results[\"Precision\"].append(precision)\n",
        "        results[\"F1 score\"].append(f1)\n",
        "        results[\"Kappa\"].append(kappa)\n",
        "        results[\"Predicted Classes\"].append(y_pred)\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(test_labels, y_prob)\n",
        "        roc_data.append((name, fpr, tpr, auc_score))\n",
        "\n",
        "    return results, roc_data\n",
        "\n",
        "num_runs = 10\n",
        "aggregate_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"AUC\": np.zeros(len(classifiers)),\n",
        "    \"Balanced Accuracy\": np.zeros(len(classifiers)),\n",
        "    \"Recall\": np.zeros(len(classifiers)),\n",
        "    \"Precision\": np.zeros(len(classifiers)),\n",
        "    \"F1 score\": np.zeros(len(classifiers)),\n",
        "    \"Kappa\": np.zeros(len(classifiers)),\n",
        "}\n",
        "\n",
        "best_results = {\n",
        "    \"Classifier\": list(classifiers.keys()),\n",
        "    \"Best Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best AUC\": [-1] * len(classifiers),\n",
        "    \"Best Balanced Accuracy\": [-1] * len(classifiers),\n",
        "    \"Best Recall\": [-1] * len(classifiers),\n",
        "    \"Best Precision\": [-1] * len(classifiers),\n",
        "    \"Best F1 score\": [-1] * len(classifiers),\n",
        "    \"Best Kappa\": [-1] * len(classifiers),\n",
        "    \"Best Predicted Classes\": [[] for _ in range(len(classifiers))]\n",
        "}\n",
        "\n",
        "# Running the evaluation multiple times\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "for run in range(num_runs):\n",
        "    results, roc_data = evaluate_classifiers(X_resampled, y_resampled, test_pre, yt_binary)\n",
        "    for i, classifier in enumerate(results[\"Classifier\"]):\n",
        "        # Update aggregate results\n",
        "        aggregate_results[\"Accuracy\"][i] += results[\"Accuracy\"][i]\n",
        "        aggregate_results[\"AUC\"][i] += results[\"AUC\"][i]\n",
        "        aggregate_results[\"Balanced Accuracy\"][i] += results[\"Balanced Accuracy\"][i]\n",
        "        aggregate_results[\"Recall\"][i] += results[\"Recall\"][i]\n",
        "        aggregate_results[\"Precision\"][i] += results[\"Precision\"][i]\n",
        "        aggregate_results[\"F1 score\"][i] += results[\"F1 score\"][i]\n",
        "        aggregate_results[\"Kappa\"][i] += results[\"Kappa\"][i]\n",
        "\n",
        "        # Update best results if the current run's accuracy is higher\n",
        "        if results[\"Accuracy\"][i] > best_results[\"Best Accuracy\"][i]:\n",
        "            best_results[\"Best Accuracy\"][i] = results[\"Accuracy\"][i]\n",
        "            best_results[\"Best AUC\"][i] = results[\"AUC\"][i]\n",
        "            best_results[\"Best Balanced Accuracy\"][i] = results[\"Balanced Accuracy\"][i]\n",
        "            best_results[\"Best Recall\"][i] = results[\"Recall\"][i]\n",
        "            best_results[\"Best Precision\"][i] = results[\"Precision\"][i]\n",
        "            best_results[\"Best F1 score\"][i] = results[\"F1 score\"][i]\n",
        "            best_results[\"Best Kappa\"][i] = results[\"Kappa\"][i]\n",
        "            best_results[\"Best Predicted Classes\"][i] = results[\"Predicted Classes\"][i]\n",
        "\n",
        "        # Append current ROC data for the classifier\n",
        "        all_roc_data[classifier].append(roc_data[i])\n",
        "\n",
        "# Calculate the average metrics for aggregate results\n",
        "for key in aggregate_results.keys():\n",
        "    if key != \"Classifier\":\n",
        "        aggregate_results[key] /= num_runs\n",
        "\n",
        "# Convert aggregate results and best results to DataFrames\n",
        "aggregate_results_df = pd.DataFrame(aggregate_results)\n",
        "best_results_df = pd.DataFrame({\n",
        "    \"Classifier\": best_results[\"Classifier\"],\n",
        "    \"Best Accuracy\": best_results[\"Best Accuracy\"],\n",
        "    \"Best AUC\": best_results[\"Best AUC\"],\n",
        "    \"Best Balanced Accuracy\": best_results[\"Best Balanced Accuracy\"],\n",
        "    \"Best Recall\": best_results[\"Best Recall\"],\n",
        "    \"Best Precision\": best_results[\"Best Precision\"],\n",
        "    \"Best F1 score\": best_results[\"Best F1 score\"],\n",
        "    \"Best Kappa\": best_results[\"Best Kappa\"]\n",
        "})\n",
        "\n",
        "# Save the aggregate and best results to an Excel file\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        aggregate_results_df.to_excel(writer, sheet_name='test_roc_fm_avg_rus', index=False)\n",
        "        best_results_df.to_excel(writer, sheet_name='test_roc_fm_best_rus', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Save the best predictions to a text file\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_fm_best_predictions_rus.txt', 'w') as f:\n",
        "    for classifier, preds in zip(best_results[\"Classifier\"], best_results[\"Best Predicted Classes\"]):\n",
        "        f.write(f\"Classifier: {classifier}\\n\")\n",
        "        f.write(\"Best Predicted Classes:\\n\")\n",
        "        for pred in preds:\n",
        "            f.write(f\"{pred}\\n\")\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Save the ROC data for later use\n",
        "with open(r'D:\\\\Dataset_koyel\\\\test_roc_fm_rus.pkl', 'wb') as file:\n",
        "    pickle.dump(best_results, file)\n",
        "    pickle.dump(all_roc_data, file)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2lioXf4-ctYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[1], roc[2], roc[3]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[3] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_fm_rus.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\test_roc_fm_rus.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OwBradm1c2XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cross validation of FM using parameter"
      ],
      "metadata": {
        "id": "QqhMrJwcc5p3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
        "from sklearn.metrics import cohen_kappa_score, roc_curve, auc, accuracy_score, recall_score, precision_score, f1_score, balanced_accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "import openpyxl\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=400),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=0.022097083970515203, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=30),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=6),\n",
        "    \"Logistic Regression\": LogisticRegression(C=0.1, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.1625, max_depth=6, n_estimators=70),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.505, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.75, learning_rate=0.1525, max_depth=8, n_estimators=300, subsample=0.75),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=100, learning_rate=0.1)\n",
        "}\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {\n",
        "    \"Classifier\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"AUC\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": [],\n",
        "    \"F1 score\": [],\n",
        "    \"Kappa\": []\n",
        "}\n",
        "\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "\n",
        "# Loop through classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=10)\n",
        "    accuracy_scores = []\n",
        "    auc_scores = []\n",
        "    bacc_scores = []\n",
        "    recall_scores = []\n",
        "    precision_scores = []\n",
        "    f1_scores = []\n",
        "    kappa_scores = []\n",
        "\n",
        "    for train_index, test_index in cv.split(train_pre, y_binary):\n",
        "        X_train, X_test = train_pre[train_index], train_pre[test_index]\n",
        "        y_train, y_test = y_binary[train_index], y_binary[test_index]\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
        "        bacc_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        kappa_scores.append(cohen_kappa_score(y_test, y_pred))\n",
        "\n",
        "        # ROC Curve data\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        all_roc_data[name].append((fpr, tpr, roc_auc))\n",
        "\n",
        "    results[\"Classifier\"].append(name)\n",
        "    results[\"Accuracy\"].append(np.mean(accuracy_scores))\n",
        "    results[\"AUC\"].append(np.mean(auc_scores))\n",
        "    results[\"Balanced Accuracy\"].append(np.mean(bacc_scores))\n",
        "    results[\"Recall\"].append(np.mean(recall_scores))\n",
        "    results[\"Precision\"].append(np.mean(precision_scores))\n",
        "    results[\"F1 score\"].append(np.mean(f1_scores))\n",
        "    results[\"Kappa\"].append(np.mean(kappa_scores))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to Excel\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\Dataset_koyel\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        results_df.to_excel(writer, sheet_name='Cv_fm', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[0], roc[1], roc[2]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[2] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize=24)\n",
        "plt.ylabel('True Positive Rate', fontsize=24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_fm.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_fm.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0wylBUvVc6b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(min_samples_leaf=1, n_estimators=400),\n",
        "    \"Support Vector Machine\": SVC(probability=True, C=1024, gamma=0.022097083970515203, kernel=\"rbf\"),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=30),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(max_depth=10, min_samples_leaf=1, min_samples_split=6),\n",
        "    \"Logistic Regression\": LogisticRegression(C=0.1, solver=\"liblinear\"),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(learning_rate=0.1625, max_depth=6, n_estimators=70),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm=\"SAMME\", learning_rate=0.505, n_estimators=237),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, colsample_bytree=0.75, learning_rate=0.1525, max_depth=8, n_estimators=300, subsample=0.75),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0, depth=5, iterations=100, learning_rate=0.1)\n",
        "}\n",
        "\n",
        "# Initialize results dictionary\n",
        "results = {\n",
        "    \"Classifier\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"AUC\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": [],\n",
        "    \"F1 score\": [],\n",
        "    \"Kappa\": []\n",
        "}\n",
        "\n",
        "all_roc_data = {name: [] for name in classifiers.keys()}\n",
        "\n",
        "# Loop through classifiers\n",
        "for name, clf in classifiers.items():\n",
        "    cv = RepeatedKFold(n_splits=5, n_repeats=10)\n",
        "    accuracy_scores = []\n",
        "    auc_scores = []\n",
        "    bacc_scores = []\n",
        "    recall_scores = []\n",
        "    precision_scores = []\n",
        "    f1_scores = []\n",
        "    kappa_scores = []\n",
        "\n",
        "    for train_index, test_index in cv.split(train_pre, y_binary):\n",
        "        X_train, X_test = train_pre[train_index], train_pre[test_index]\n",
        "        y_train, y_test = y_binary[train_index], y_binary[test_index]\n",
        "\n",
        "        # Apply Random Oversampling to the training data\n",
        "        #ros = RandomOverSampler(random_state=42)\n",
        "        #X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
        "\n",
        "        #Random undersampling\n",
        "        rus = RandomUnderSampler(random_state=42)# fit predictor and target variable not a good option\n",
        "        X_train_resampled, y_train_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "        #smote = SMOTE(random_state=42)\n",
        "        #X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "        clf.fit(X_train_resampled, y_train_resampled)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
        "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
        "        bacc_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
        "        recall_scores.append(recall_score(y_test, y_pred))\n",
        "        precision_scores.append(precision_score(y_test, y_pred))\n",
        "        f1_scores.append(f1_score(y_test, y_pred))\n",
        "        kappa_scores.append(cohen_kappa_score(y_test, y_pred))\n",
        "\n",
        "        # ROC Curve data\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        all_roc_data[name].append((fpr, tpr, roc_auc))\n",
        "\n",
        "    results[\"Classifier\"].append(name)\n",
        "    results[\"Accuracy\"].append(np.mean(accuracy_scores))\n",
        "    results[\"AUC\"].append(np.mean(auc_scores))\n",
        "    results[\"Balanced Accuracy\"].append(np.mean(bacc_scores))\n",
        "    results[\"Recall\"].append(np.mean(recall_scores))\n",
        "    results[\"Precision\"].append(np.mean(precision_scores))\n",
        "    results[\"F1 score\"].append(np.mean(f1_scores))\n",
        "    results[\"Kappa\"].append(np.mean(kappa_scores))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to Excel\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\Dataset_koyel\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        results_df.to_excel(writer, sheet_name='Cv_fm_rus', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# Plot ROC curves\n",
        "plt.figure(figsize=(10, 10))\n",
        "for name, roc_list in all_roc_data.items():\n",
        "    mean_fpr = np.linspace(0, 1, 100)\n",
        "    mean_tpr = np.zeros_like(mean_fpr)\n",
        "    for roc in roc_list:\n",
        "        fpr, tpr, auc_score = roc[0], roc[1], roc[2]\n",
        "        mean_tpr += np.interp(mean_fpr, fpr, tpr)\n",
        "    mean_tpr /= len(roc_list)\n",
        "    mean_auc = np.mean([roc[2] for roc in roc_list])\n",
        "    plt.plot(mean_fpr, mean_tpr, lw=2, label=f'{name} (AUC = {mean_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='r', lw=2, label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate', fontsize = 24)\n",
        "plt.ylabel('True Positive Rate', fontsize = 24)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Adjust legend position and font size\n",
        "plt.legend(loc=\"upper center\", fontsize=18, ncol=2, bbox_to_anchor=(0.5, -0.1))\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_fm_rus.eps', format='eps', bbox_inches='tight')\n",
        "plt.savefig(r'D:\\\\Dataset_koyel\\\\cv_fm_rus.png', format='png', bbox_inches='tight')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yiOX0_fVc9mP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Classification algorithms\n",
        "#y_binary = final_df['Class']\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "import xgboost as xgb\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "# Assuming you have train_pre and test_pre datasets, and y_binary (training labels)\n",
        "\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm = \"SAMME\"),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
        "}\n",
        "\n",
        "# Placeholder for storing predictions\n",
        "predictions = {}\n",
        "\n",
        "# Fit each classifier on the training data and make predictions on the testing data\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(train_pre, y_binary)\n",
        "    y_pred = clf.predict(test_pre)\n",
        "    predictions[name] = y_pred\n",
        "    #print(f\"{name} predictions: {np.unique(y_pred)}\")\n",
        "\n",
        "# Convert predictions dictionary to DataFrame for easier handling\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "# Save predictions to an Excel file\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        predictions_df.to_excel(writer, sheet_name='Test_Predictions', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "2eYCw86Kc_3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now apply classification algorithm. The preprocessed data is saved in preprocessed_data_oral_DB_df.csv file. or input_df dataframe"
      ],
      "metadata": {
        "id": "SiKLZ2hadEZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(algorithm = \"SAMME\"),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, learning_rate=0.01)\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose=0)\n",
        "}\n",
        "\n",
        "# Apply Random Oversampling to the training data\n",
        "#ros = RandomOverSampler(random_state=42)\n",
        "#X_resampled, y_resampled = ros.fit_resample(train_pre, y_binary)\n",
        "\n",
        "#Random undersampling\n",
        "rus = RandomUnderSampler(random_state=42, replacement=True)# fit predictor and target variable not a good option\n",
        "X_resampled, y_resampled = rus.fit_resample(train_pre, y_binary)\n",
        "\n",
        "\n",
        "#smote = SMOTE(random_state=42)\n",
        "#X_resampled, y_resampled = smote.fit_resample(train_pre, y_binary)\n",
        "\n",
        "# Ensure the resampled data is in DataFrame and Series format\n",
        "X_resampled = pd.DataFrame(X_resampled)\n",
        "y_resampled = pd.Series(y_resampled)\n",
        "\n",
        "# Save the resampled data for inspection\n",
        "merged_sampling = pd.concat([X_resampled, y_resampled], axis=1)\n",
        "#with pd.ExcelWriter('D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "#    merged_sampling.to_excel(writer, sheet_name='sampling_data', index=False)\n",
        "\n",
        "# Placeholder for storing predictions\n",
        "predictions = {}\n",
        "\n",
        "# Train classifiers on the resampled data and predict on test data\n",
        "for name, clf in classifiers.items():\n",
        "    clf.fit(X_resampled, y_resampled)  # Train the classifier\n",
        "    y_pred = clf.predict(test_pre)  # Predict on test data\n",
        "    predictions[name] = y_pred  # Store predictions\n",
        "\n",
        "# Convert predictions dictionary to DataFrame for easier handling\n",
        "predictions_df = pd.DataFrame(predictions)\n",
        "\n",
        "# Save predictions to an Excel file\n",
        "try:\n",
        "    with pd.ExcelWriter(r'D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        predictions_df.to_excel(writer, sheet_name='Test_Predictions_under', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "GweZr4crdFZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score, roc_auc_score, balanced_accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC(probability=True),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
        "    \"Extreme Gradient Boosting\": xgb.XGBClassifier(random_state=1, learning_rate=0.01),\n",
        "    \"CatBoost Classifier\": CatBoostClassifier(verbose = 0)\n",
        "}\n",
        "\n",
        "# Define metrics to be collected\n",
        "results = {\n",
        "    \"Classifier\": [],\n",
        "    \"Accuracy\": [],\n",
        "    \"AUC\": [],\n",
        "    \"Balanced Accuracy\": [],\n",
        "    \"Recall\": [],\n",
        "    \"Precision\": [],\n",
        "    \"F1 score\": [],\n",
        "    \"Kappa\": []\n",
        "}\n",
        "\n",
        "# Assume X_pre and y_binary are your original features and labels\n",
        "# Ensure X_pre and y_binary are numpy arrays\n",
        "X_pre = np.array(train_merged_array)\n",
        "y_binary = np.array(y_binary)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pre, y_binary, test_size=0.2)\n",
        "\n",
        "# Apply SMOTE only on the training data\n",
        "smote = SMOTE(random_state=42)\n",
        "#ros = RandomOverSampler(random_state=42)\n",
        "#rus = RandomUnderSampler(random_state = 42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
        "#X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Evaluate each classifier\n",
        "for name, clf in classifiers.items():\n",
        "    # Train and evaluate the classifier\n",
        "    clf.fit(X_resampled, y_resampled)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "    # Store results\n",
        "    results[\"Classifier\"].append(name)\n",
        "    results[\"Accuracy\"].append(accuracy)\n",
        "    results[\"AUC\"].append(auc)\n",
        "    results[\"Balanced Accuracy\"].append(balanced_accuracy)\n",
        "    results[\"Recall\"].append(recall)\n",
        "    results[\"Precision\"].append(precision)\n",
        "    results[\"F1 score\"].append(f1)\n",
        "    results[\"Kappa\"].append(kappa)\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Save results to Excel\n",
        "try:\n",
        "    with pd.ExcelWriter('D:\\\\Dataset_koyel\\\\intermediate_result.xlsx', engine='openpyxl', mode='a') as writer:\n",
        "        results_df.to_excel(writer, sheet_name='Result_simple_split2', index=False)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)\n"
      ],
      "metadata": {
        "id": "bJyjkTAkdIUQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}